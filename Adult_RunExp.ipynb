{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit6f19452678144e6e97437b4df42ffca5",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Documents\\\\U4 Academics\\\\Winter 2020\\\\COMP 551-Applied Machine Learning\\\\Assignments\\\\Assignment 1\\\\COMP551A1\\\\Dataset_Folder\\\\Dataset2_Adult'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-833fbbb77683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#PREPROCESS DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData_Preprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_preprocess_adultData\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_adult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/COMP551A1/Data_Preprocessing/data_preprocess_adultData.py\u001b[0m in \u001b[0;36mpreprocess_adult\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# data folder path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdataFolderPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D:\\\\Documents\\\\U4 Academics\\\\Winter 2020\\\\COMP 551-Applied Machine Learning\\\\Assignments\\\\Assignment 1\\\\COMP551A1\\\\Dataset_Folder\\\\Dataset2_Adult'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataFolderPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;31m# retreving the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adult_index.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Documents\\\\U4 Academics\\\\Winter 2020\\\\COMP 551-Applied Machine Learning\\\\Assignments\\\\Assignment 1\\\\COMP551A1\\\\Dataset_Folder\\\\Dataset2_Adult'"
     ]
    }
   ],
   "source": [
    "#PREPROCESS DATA\n",
    "import Data_Preprocessing.data_preprocess_adultData as preprocess \n",
    "features, feature_types, labels= preprocess.preprocess_adult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KCROSS FOLD VALIDATION\n",
    "import Models.kfold_CV_try as cv\n",
    "\n",
    "# Train test split\n",
    "xTrain_adult, xTest_adult, yTrain_adult, yTest_adult = cv.split_train_test(features, labels, 0.2)\n",
    "print(yTrain_adult);print(yTest_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5 # delete folds later when embedded in function input\n",
    "# cv_train_data_ion is xTrain_ion split into five chunks\n",
    "dataset_split_in, cv_train_data_adult,cv_train_label_adult= cv.kfold_cross_validation(xTrain_adult,yTrain_adult,folds)\n",
    "# print(cv_train_data_ion,cv_train_label_ion)\n",
    "\n",
    "# the last input for cv.train_validation_split is the number of experiments you are running currently, 5 in total. \n",
    "# each experiments is organizing the five chunks from cv_train_data_ion into 4 chunks for training_data_ion and 1 chunk for validate_data_ion for cross validation, just need to uncomment the line you want to experiment currently. \n",
    "\n",
    "# will be in a for-loop when computing accuracy scores \n",
    "#exp1: \n",
    "validate_data_adult,validate_labels_adult,training_data_adult,training_labels_adult = cv.train_validation_split(cv_train_data_adult,cv_train_label_adult,1)\n",
    "\n",
    "#exp2:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,2)\n",
    "\n",
    "#exp3:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,3)\n",
    "\n",
    "#exp4:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,4)\n",
    "\n",
    "#exp5: \n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,5)\n",
    "print(validate_data_adult,validate_labels_adult)\n",
    "print(validate_data_adult.shape,validate_labels_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "import Models.logisticRegression as lr\n",
    "adultlr1 = lr.Logistic_Regression(0.02,\"Ionosphere\",\"binary\") # input step size\n",
    "# params = ionslr1.fit(cv_train_data, cv_train_label, 0.02, 1e-1)\n",
    "params = adultlr1.fit(training_data_adult,training_labels_adult,0.02,1e-1)\n",
    "print(params)\n",
    "results= adultlr1.predict(params, xTest_adult)\n",
    "print(results)\n",
    "#adding a separate comment\n",
    "# input learning rate and termination conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACCURACY"
   ]
  }
 ]
}