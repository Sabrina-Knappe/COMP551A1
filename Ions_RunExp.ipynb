{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit16c59f3069ba44c59fdc0e453d119bc5",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1  0  0.99539  -0.05889  0.85243  0.02306  0.83398  -0.37708      1.1  \\\n0    1  0  1.00000  -0.18829  0.93035 -0.36156 -0.10868  -0.93597  1.00000   \n1    1  0  1.00000  -0.03365  1.00000  0.00485  1.00000  -0.12062  0.88965   \n2    1  0  1.00000  -0.45161  1.00000  1.00000  0.71216  -1.00000  0.00000   \n3    1  0  1.00000  -0.02401  0.94140  0.06531  0.92106  -0.23255  0.77152   \n4    1  0  0.02337  -0.00592 -0.09924 -0.11949 -0.00763  -0.11824  0.14706   \n5    1  0  0.97588  -0.10602  0.94601 -0.20800  0.92806  -0.28350  0.85996   \n6    0  0  0.00000   0.00000  0.00000  0.00000  1.00000  -1.00000  0.00000   \n7    1  0  0.96355  -0.07198  1.00000 -0.14333  1.00000  -0.21313  1.00000   \n8    1  0 -0.01864  -0.08459  0.00000  0.00000  0.00000   0.00000  0.11470   \n9    1  0  1.00000   0.06655  1.00000 -0.18388  1.00000  -0.27320  1.00000   \n10   1  0  1.00000  -0.54210  1.00000 -1.00000  1.00000  -1.00000  1.00000   \n11   1  0  1.00000  -0.16316  1.00000 -0.10169  0.99999  -0.15197  1.00000   \n12   1  0  1.00000  -0.86701  1.00000  0.22280  0.85492  -0.39896  1.00000   \n13   1  0  1.00000   0.07380  1.00000  0.03420  1.00000  -0.05563  1.00000   \n14   1  0  0.50932  -0.93996  1.00000  0.26708 -0.03520  -1.00000  1.00000   \n15   1  0  0.99645   0.06468  1.00000 -0.01236  0.97811   0.02498  0.96112   \n16   0  0  0.00000   0.00000 -1.00000 -1.00000  1.00000   1.00000 -1.00000   \n17   1  0  0.67065   0.02528  0.66626  0.05031  0.57197   0.18761  0.08776   \n18   0  0  1.00000  -1.00000  0.00000  0.00000  0.00000   0.00000  1.00000   \n19   1  0  1.00000  -0.00612  1.00000 -0.09834  1.00000  -0.07649  1.00000   \n20   0  0  1.00000   1.00000  0.00000  0.00000  0.00000   0.00000 -1.00000   \n21   1  0  0.96071   0.07088  1.00000  0.04296  1.00000   0.09313  0.90169   \n22   0  0 -1.00000   1.00000  0.00000  0.00000  0.00000   0.00000 -1.00000   \n23   1  0  1.00000  -0.06182  1.00000  0.02942  1.00000  -0.05131  1.00000   \n24   1  0  1.00000   0.57820  1.00000 -1.00000  1.00000  -1.00000  1.00000   \n25   1  0  1.00000  -0.08714  1.00000 -0.17263  0.86635  -0.81779  0.94817   \n26   0  0 -1.00000  -1.00000  0.00000  0.00000 -1.00000   1.00000  1.00000   \n27   1  0  1.00000   0.08380  1.00000  0.17387  1.00000  -0.13308  0.98172   \n28   0  0 -1.00000  -1.00000  1.00000  1.00000  1.00000  -1.00000 -1.00000   \n29   1  0  1.00000  -0.14236  1.00000 -0.16256  1.00000  -0.23656  1.00000   \n..  .. ..      ...       ...      ...      ...      ...       ...      ...   \n320  1  0  0.89505  -0.03168  0.87525  0.05545  0.89505   0.01386  0.92871   \n321  1  0  0.90071   0.01773  1.00000 -0.01773  0.90071   0.00709  0.84752   \n322  1  0  0.39394  -0.24242  0.62655  0.01270  0.45455   0.09091  0.63636   \n323  1  0  0.86689   0.35950  0.72014  0.66667  0.37201   0.83049  0.08646   \n324  1  0  0.89563   0.37917  0.67311  0.69438  0.35916   0.88696 -0.04193   \n325  1  0  0.90547   0.41113  0.65354  0.74761  0.29921   0.95905 -0.13342   \n326  1  0  1.00000   1.00000  0.36700  0.06158  0.12993   0.92713 -0.27586   \n327  1  0  1.00000   0.51515  0.45455  0.33333  0.06061   0.36364 -0.32104   \n328  1  0  0.88110   0.00000  0.94817 -0.02744  0.93598  -0.01220  0.90244   \n329  1  0  0.82624   0.08156  0.79078 -0.08156  0.90426  -0.01773  0.92908   \n330  1  0  0.74468   0.10638  0.88706  0.00982  0.88542   0.01471  0.87234   \n331  1  0  0.87578   0.03727  0.89951  0.00343  0.89210   0.00510  0.86335   \n332  1  0  0.97513   0.00710  0.98579  0.01954  1.00000   0.01954  0.99290   \n333  1  0  1.00000   0.01105  1.00000  0.01105  1.00000   0.02320  0.99448   \n334  1  0  1.00000  -0.01342  1.00000  0.01566  1.00000  -0.00224  1.00000   \n335  1  0  0.88420   0.36724  0.67123  0.67382  0.39613   0.86399  0.02424   \n336  1  0  0.90147   0.41786  0.64131  0.75725  0.30440   0.95148 -0.20449   \n337  1  0  0.32789   0.11042  0.15970  0.29308  0.14020   0.74485 -0.25131   \n338  1  0  0.65845   0.43617  0.44681  0.74804  0.05319   0.85106 -0.32027   \n339  1  0  0.19466   0.05725  0.04198  0.25191 -0.10557   0.48866 -0.18321   \n340  1  0  0.98002   0.00075  1.00000  0.00000  0.98982  -0.00075  0.94721   \n341  1  0  0.82254  -0.07572  0.80462  0.00231  0.87514  -0.01214  0.86821   \n342  1  0  0.35346  -0.13768  0.69387 -0.02423  0.68195  -0.03574  0.55717   \n343  1  0  0.76046   0.01092  0.86335  0.00258  0.85821   0.00384  0.79988   \n344  1  0  0.66667  -0.01366  0.97404  0.06831  0.49590   0.50137  0.75683   \n345  1  0  0.83508   0.08298  0.73739 -0.14706  0.84349  -0.05567  0.90441   \n346  1  0  0.95113   0.00419  0.95183 -0.02723  0.93438  -0.01920  0.94590   \n347  1  0  0.94701  -0.00034  0.93207 -0.03227  0.95177  -0.03431  0.95584   \n348  1  0  0.90608  -0.01657  0.98122 -0.01989  0.95691  -0.03646  0.85746   \n349  1  0  0.84710   0.13533  0.73638 -0.06151  0.87873   0.08260  0.88928   \n\n     0.03760  ...  -0.51171  0.41078  -0.46168  0.21266  -0.34090  0.42267  \\\n0   -0.04549  ...  -0.26569 -0.20468  -0.18401 -0.19040  -0.11593 -0.16626   \n1    0.01198  ...  -0.40220  0.58984  -0.22145  0.43100  -0.17365  0.60436   \n2    0.00000  ...   0.90695  0.51613   1.00000  1.00000  -0.20099  0.25682   \n3   -0.16399  ...  -0.65158  0.13290  -0.53206  0.02431  -0.62197 -0.05707   \n4    0.06637  ...  -0.01535 -0.03240   0.09223 -0.07859   0.00732  0.00000   \n5   -0.27342  ...  -0.81634  0.13659  -0.82510  0.04606  -0.82395 -0.04262   \n6    0.00000  ...   1.00000  1.00000   1.00000  0.00000   0.00000  1.00000   \n7   -0.36174  ...  -0.65440  0.57577  -0.69712  0.25435  -0.63919  0.45114   \n8   -0.26810  ...  -0.01326  0.20645  -0.02294  0.00000   0.00000  0.16595   \n9   -0.43107  ...  -0.89128  0.47211  -0.86500  0.40303  -0.83675  0.30996   \n10   0.36217  ...  -0.40888  1.00000  -0.62745  1.00000  -1.00000  1.00000   \n11  -0.19277  ...  -0.47137  0.76224  -0.58370  0.65723  -0.68794  0.68714   \n12  -0.12090  ...  -0.17012  1.00000   0.35924  1.00000  -0.66494  1.00000   \n13   0.08764  ...   0.20033  1.00000   0.36743  0.95603   0.48641  1.00000   \n14  -1.00000  ...   0.92236  0.39752   0.26501  0.00000   0.00000  1.00000   \n15   0.02312  ...   0.13412  0.79476   0.13638  0.79110   0.15379  0.77122   \n16   1.00000  ...   1.00000  1.00000  -1.00000 -1.00000   1.00000 -1.00000   \n17   0.34081  ...   0.23724  0.46167   0.24618  0.43433   0.25306  0.40663   \n18   1.00000  ...   1.00000  1.00000   1.00000  1.00000  -1.00000  1.00000   \n19  -0.10605  ...  -0.40372  0.82681  -0.42231  0.75784  -0.38231  0.80448   \n20  -1.00000  ...   0.00000  1.00000  -1.00000 -1.00000   1.00000 -1.00000   \n21  -0.05144  ...  -0.07705  0.58051  -0.02205  0.49664  -0.01251  0.51310   \n22   1.00000  ...  -1.00000  1.00000  -1.00000  1.00000   1.00000 -1.00000   \n23  -0.01707  ...  -0.34838  0.72529  -0.29174  0.73094  -0.38576  0.54356   \n24  -1.00000  ...  -1.00000  1.00000  -1.00000  1.00000  -1.00000  1.00000   \n25   0.61053  ...  -0.82868  0.48136  -0.86583  0.40650  -0.89674  0.32984   \n26  -0.37500  ...  -1.00000 -1.00000   1.00000 -1.00000  -1.00000  0.00000   \n27   0.64520  ...   1.00000  0.83899   1.00000  0.74822   1.00000  0.64358   \n28   1.00000  ...   1.00000  1.00000  -1.00000  1.00000  -1.00000 -1.00000   \n29  -0.07514  ...  -0.47643  0.98820  -0.49687  1.00000  -0.75820  1.00000   \n..       ...  ...       ...      ...       ...      ...       ...      ...   \n320  0.02772  ...   0.02376  0.89002   0.01611  0.88119   0.00198  0.87327   \n321  0.05674  ...   0.04610  0.94305   0.03247  0.94681   0.02482  1.00000   \n322  0.09091  ...   0.05929  0.46362   0.06142  0.33333  -0.03030  0.41856   \n323  0.85893  ...  -0.59954  0.15360  -0.53127  0.32309  -0.37088  0.46189   \n324  0.93345  ...  -0.73856  0.33531  -0.62296  0.52414  -0.42086  0.61217   \n325  0.97820  ...  -0.85368  0.67538  -0.61959  0.85977  -0.28123  0.88654   \n326  0.93596  ...  -0.45950  0.85471  -0.06831  1.00000   1.00000  0.38670   \n327  0.73062  ...  -0.39394  0.72961   0.12331  0.96970   0.57576  0.24242   \n328  0.01829  ...   0.04878  0.89666   0.02226  0.90854   0.00915  1.00000   \n329  0.01064  ...   0.15957  0.89527   0.08165  0.77660   0.06738  0.92553   \n330 -0.01418  ...   0.11348  0.83429   0.06014  0.74468  -0.03546  0.81710   \n331  0.00000  ...  -0.04348  0.82111   0.02033  0.81988   0.08696  0.80757   \n332  0.01599  ...   0.03552  0.97540   0.06477  0.94849   0.08171  0.99112   \n333 -0.01436  ...  -0.00663  0.98033   0.01600  0.97901   0.01547  0.98564   \n334  0.06264  ...   0.10067  0.99989   0.08763  0.99105   0.08501  1.00000   \n335  0.93182  ...  -0.69774  0.26028  -0.60678  0.44569  -0.43383  0.54209   \n336  0.96534  ...  -0.82154  0.74105  -0.55231  0.89415  -0.18725  0.87893   \n337  0.91993  ...  -0.18560  0.39599  -0.11498  0.31005   0.05614  0.21443   \n338  0.82139  ...  -0.18645  0.74758   0.23713  0.45185   0.59071  0.20549   \n339 -0.18321  ...   0.24692  0.03913   0.31092 -0.03817   0.26336 -0.16794   \n340  0.02394  ...   0.08107  0.96709   0.07255  0.95701   0.08088  0.98190   \n341 -0.07514  ...  -0.02370  0.76717  -0.02731  0.74046  -0.07630  0.70058   \n342 -0.06119  ...  -0.00564  0.39146  -0.09038  0.35588  -0.10306  0.32232   \n343  0.02304  ...  -0.00303  0.70886   0.01375  0.66161   0.00849  0.66298   \n344 -0.00273  ...   0.06967  0.68656   0.17088  0.87568   0.07787  0.55328   \n345 -0.04622  ...  -0.04202  0.83479   0.00123  1.00000   0.12815  0.86660   \n346  0.01606  ...   0.01361  0.93522   0.04925  0.93159   0.08168  0.94066   \n347  0.02446  ...   0.03193  0.92489   0.02542  0.92120   0.02242  0.92459   \n348  0.00110  ...  -0.02099  0.89147  -0.07760  0.82983  -0.17238  0.96022   \n349 -0.09139  ...  -0.15114  0.81147  -0.04822  0.78207  -0.00703  0.75747   \n\n     -0.54487  0.18641  -0.45300  g  \n0    -0.06288 -0.13738  -0.02447  b  \n1    -0.24180  0.56045  -0.38238  g  \n2     1.00000 -0.32382   1.00000  b  \n3    -0.59573 -0.04608  -0.65697  g  \n4     0.00000 -0.00039   0.12011  b  \n5    -0.81318 -0.13832  -0.80975  g  \n6     1.00000  0.00000   0.00000  b  \n7    -0.72779  0.38895  -0.73420  g  \n8     0.24086 -0.08208   0.38065  b  \n9    -0.89093  0.22995  -0.89158  g  \n10   -1.00000  1.00000  -1.00000  b  \n11   -0.64537  0.64727  -0.67226  g  \n12    0.88428  1.00000  -0.18826  b  \n13    0.32492  1.00000   0.46712  g  \n14    0.23188  0.00000   0.00000  b  \n15    0.15930  0.70941   0.12015  g  \n16   -1.00000  1.00000  -1.00000  b  \n17    0.25792  1.00000   0.33036  g  \n18    1.00000  1.00000   1.00000  b  \n19   -0.40575  0.74354  -0.45039  g  \n20    1.00000 -1.00000   1.00000  b  \n21   -0.00015  0.52099  -0.00182  g  \n22    1.00000  0.00000   0.00000  b  \n23   -0.26284  0.64207  -0.39487  g  \n24   -1.00000  1.00000  -1.00000  b  \n25   -0.92128 -0.13341  -1.00000  g  \n26    0.00000 -1.00000   1.00000  b  \n27    1.00000  0.52479   1.00000  g  \n28    1.00000  1.00000  -1.00000  b  \n29   -0.75761  1.00000  -0.84437  g  \n..        ...      ...       ... ..  \n320   0.04158  0.86733   0.02376  g  \n321   0.01064  0.93617   0.02128  g  \n322   0.06410  0.39394   0.24242  g  \n323  -0.19681  0.40956   0.01820  g  \n324  -0.17343  0.60073   0.08660  g  \n325   0.09800  0.75495   0.46301  g  \n326   0.00246  0.17758   0.79790  g  \n327   0.36364  0.09091   0.33333  g  \n328   0.05488  0.97561  -0.01220  g  \n329   0.18085  0.92553   0.00000  g  \n330   0.06800  0.80774   0.07173  g  \n331   0.02308  0.80088   0.02441  g  \n332   0.06217  0.98934   0.09947  g  \n333   0.02099  0.98674   0.02762  g  \n334   0.10067  1.00000   0.10067  g  \n335  -0.21542  0.56286   0.02823  g  \n336   0.20359  0.70555   0.54852  g  \n337   0.20540  0.13376   0.26422  g  \n338   0.76764 -0.18533   0.74356  g  \n339   0.16794 -0.30153  -0.33588  g  \n340   0.08126  0.97247   0.08616  g  \n341  -0.04220  0.78439   0.01214  g  \n342  -0.08637  0.28943  -0.08300  g  \n343   0.01484  0.63887   0.01525  g  \n344   0.24590  0.13934   0.48087  g  \n345  -0.10714  0.90546  -0.04307  g  \n346  -0.00035  0.91483   0.04712  g  \n347   0.00442  0.92697  -0.00577  g  \n348  -0.03757  0.87403  -0.16243  g  \n349  -0.06678  0.85764  -0.06151  g  \n\n[350 rows x 35 columns]\n"
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'ionosphere-data.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('ionosphere-data.csv', sep=',')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g']\n"
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Convert to numpy\n",
    "#df.to_numpy()\n",
    "temp = df.values\n",
    "R,C = temp.shape\n",
    "#print(C)\n",
    "\n",
    "# Split array into design matrix and labels\n",
    "ionosphere_labels = temp[:, C-1]\n",
    "print(ionosphere_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1 0 1.0 ... -0.06287999999999999 -0.13738 -0.02447]\n [1 0 1.0 ... -0.2418 0.56045 -0.38238]\n [1 0 1.0 ... 1.0 -0.32382 1.0]\n ...\n [1 0 0.94701 ... 0.00442 0.9269700000000001 -0.00577]\n [1 0 0.9060799999999999 ... -0.03757 0.87403 -0.16243]\n [1 0 0.8471 ... -0.06677999999999999 0.85764 -0.06151]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Remove labels to get design matrix\n",
    "ionosphere_design_matrix= np.delete(temp, C-1, 1)\n",
    "print(ionosphere_design_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Models.kfold_CV_try as cv\n",
    "\n",
    "# Train test split\n",
    "xTrain_ion, xTest_ion, yTrain_ion, yTest_ion = cv.split_train_test(ionosphere_design_matrix, ionosphere_labels, 0.2)\n",
    "# print(xTest_ion); print(xTrain_ion); print(yTest_ion);print(yTrain_ion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1 0 0.73523 ... 0.49721000000000004 0.30588000000000004\n  0.49831000000000003]\n [1 0 1.0 ... -0.88846 0.29220999999999997 -0.8962100000000001]\n [1 0 0.62121 ... -0.02273 0.17045 -0.41667]\n ...\n [1 0 1.0 ... -0.44505 -0.37432 -0.5331899999999999]\n [1 0 0.64122 ... 0.0 0.17073 0.07317]\n [1 0 0.8941 ... 0.19172 -0.48808 0.05972]] ['g' 'g' 'b' 'g' 'g' 'g' 'g' 'g' 'b' 'b' 'b' 'g' 'g' 'b' 'b' 'b' 'g' 'b'\n 'g' 'g' 'g' 'g' 'g' 'g' 'b' 'g' 'b' 'b' 'g' 'b' 'b' 'b' 'b' 'g' 'b' 'g'\n 'b' 'g' 'g' 'g' 'g' 'b' 'b' 'g' 'g' 'g' 'b' 'g' 'g' 'g' 'b' 'b' 'g' 'g'\n 'g' 'g']\n(56, 34) (56,)\n"
    }
   ],
   "source": [
    "folds = 5 # delete folds later when embedded in function input\n",
    "# cv_train_data_ion is xTrain_ion split into five chunks\n",
    "dataset_split_in, cv_train_data_ion,cv_train_label_ion= cv.kfold_cross_validation(xTrain_ion,yTrain_ion,folds)\n",
    "# print(cv_train_data_ion,cv_train_label_ion)\n",
    "\n",
    "# the last input for cv.train_validation_split is the number of experiments you are running currently, 5 in total. \n",
    "# each experiments is organizing the five chunks from cv_train_data_ion into 4 chunks for training_data_ion and 1 chunk for validate_data_ion, just need to uncomment the line you want to experiment currently. \n",
    "\n",
    "#exp1: \n",
    "validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,1)\n",
    "\n",
    "#exp2:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,2)\n",
    "\n",
    "#exp3:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,3)\n",
    "\n",
    "#exp4:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,4)\n",
    "\n",
    "#exp5: \n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,5)\n",
    "print(validate_data_ion,validate_labels_ion)\n",
    "print(validate_data_ion.shape,validate_labels_ion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Now fitting Ionosphere\n0.59425587954494\n0.5784580103373067\n0.5631928737952374\n0.5484522504666035\n0.5342264361744569\n0.5205045035018748\n0.507274538304543\n0.4945238515629254\n0.4822391674113059\n0.470406788558032\n0.4590127405640159\n0.44804289659791624\n0.4374830843573174\n0.427319176854095\n0.4175371687247412\n0.4081232396559324\n0.399063806422743\n0.3903455649302364\n0.38195552353532397\n0.37388102880984964\n0.36610978479153927\n0.35862986665938157\n0.3514297296659656\n0.3444982140623847\n0.3378245466621106\n0.3313983396089488\n0.3252095868407395\n0.3192486586745675\n0.31350629488052134\n0.3079735965589838\n0.3026420170905262\n0.2975033523871859\n0.29254973063867146\n0.2877736017163712\n0.28316772637142856\n0.2787251653401397\n0.27443926845012123\n0.27030366380367427\n0.2663122471002233\n0.2624591711472942\n0.2587388355989627\n0.2551458769517784\n0.2516751588206638\n0.24832176251097973\n0.2450809778976911\n0.2419482946182023\n0.23891939358183198\n0.23599013879595626\n0.23315656950645544\n0.23041489264819273\n0.22776147559972987\n0.22519283923531255\n0.22270565126625766\n0.22029671986321805\n0.21796298755033575\n0.2157015253619954\n0.21350952725272232\n0.21138430475071363\n0.20932328184552004\n0.20732399010050087\n0.20538406398082912\n0.2035012363880272\n0.20167333439224844\n0.19989827515377612\n0.19817406202549062\n0.19649878082834046\n0.19487059629214695\n0.19328774865437195\n0.1917485504097677\n0.1902513832041285\n0.18879469486564213\n0.18737699656763154\n0.18599686011673877\n0.18465291536087713\n0.18334384771152984\n0.1820683957752175\n0.18082534908919912\n0.17961354595669296\n0.17843187137712302\n0.17727925506710585\n0.17615466956808915\n0.1750571284367426\n0.17398568451438567\n0.172939428271904\n0.171917486226774\n0.1709190194289706\n0.1699432220126811\n0.16898931981089002\n0.16805656903003532\n0.16714425498206426\n0.1662516908713392\n0.16537821663396055\n0.1645231978271845\n0.16368602456671935\n0.1628661105097832\n0.162062891881904\n0.16127582654553232\n0.16050439310862386\n0.15974809007143462\n0.159006435009846\n0.1582789637936177\n0.1575652298380328\n0.15686480338747336\n0.1561772708295254\n0.1555022340382782\n0.15483930974554092\n0.1541881289387552\n0.15354833628443926\n0.1529195895760497\n0.15230155920519517\n0.15169392765518575\n0.15109638901594546\n0.1505086485193594\n0.14993042209416665\n0.1493614359395511\n0.14880142611661917\n0.14825013815698912\n0.14770732668775013\n0.1471727550720853\n0.14664619506487883\n0.1461274264826626\n0.1456162368872829\n0.14511242128269525\n0.14461578182432444\n0.1441261275404467\n0.14364327406508012\n0.14316704338188832\n0.142697263578625\n0.14223376861167\n0.1417763980802233\n0.14132499700974546\n0.14087941564425122\n0.14043950924707704\n0.14000513790976396\n0.1395761663687099\n0.1391524638292623\n0.1387339037969361\n0.13832036391545455\n0.13791172581132619\n0.13750787494468034\n0.13710870046609966\n0.13671409507919527\n0.13632395490868496\n0.13593817937374275\n0.13555667106639974\n0.13517933563478396\n0.13480608167099914\n0.1344368206034466\n0.1340714665934078\n0.13370993643570847\n0.133352149463297\n0.1329980274555734\n0.1326474945503145\n0.13230047715904716\n0.1319569038857271\n0.1316167054485874\n0.13127981460502702\n0.1309461660794137\n0.13061569649368357\n0.13028834430062172\n0.12996404971971498\n0.12964275467547298\n0.129324402738116\n0.12900893906653416\n0.12869631035342619\n0.12838646477252968\n0.1280793519278581\n0.12777492280486355\n0.1274731297234494\n0.12717392629275637\n0.12687726736765273\n0.1265831090068598\n0.1262914084326479\n0.12600212399203922\n0.1257152151194594\n0.1254306423007786\n0.1251483670386883\n0.12486835181936023\n0.12459056008033748\n0.12431495617960846\n0.12404150536581819\n0.12377017374957151\n0.12350092827578586\n0.12323373669705236\n0.12296856754796605\n0.12270539012038767\n0.12244417443960007\n0.12218489124132564\n0.12192751194957036\n0.12167200865526327\n0.12141835409566053\n0.12116652163448408\n0.12091648524276738\n0.12066821948038095\n0.12042169947821134\n0.12017690092096904\n0.11993380003060078\n0.11969237355028403\n0.11945259872898065\n0.11921445330652924\n0.11897791549925571\n0.11874296398608161\n0.11850957789511309\n0.1182777367906908\n0.11804742066088467\n0.11781860990541602\n0.11759128532399125\n0.11736542810503267\n0.11714101981478982\n0.11691804238681913\n0.11669647811181692\n0.11647630962779315\n0.11625751991057358\n0.11604009226461748\n0.11582401031414023\n0.11560925799452895\n0.11539581954404071\n0.11518367949577304\n0.11497282266989618\n0.11476323416613922\n0.11455489935651847\n0.11434780387830158\n0.11414193362719753\n0.1139372747507646\n0.11373381364202911\n0.11353153693330637\n0.1133304314902174\n0.11313048440589411\n0.11293168299536638\n0.11273401479012399\n0.11253746753284838\n0.11234202917230689\n0.11214768785840487\n0.11195443193738924\n0.11176224994719888\n0.1115711306129562\n0.11138106284259527\n0.11119203572262155\n0.11100403851399886\n0.11081706064815892\n0.11063109172312972\n0.11044612149977759\n0.11026213989816074\n0.11007913699398839\n0.10989710301518393\n0.10971602833854699\n0.10953590348651185\n0.10935671912399886\n0.10917846605535535\n0.10900113522138366\n0.10882471769645266\n0.10864920468569055\n0.1084745875222558\n0.10830085766468399\n0.10812800669430761\n0.10795602631274712\n0.10778490833946998\n0.10761464470941613\n0.10744522747068765\n0.10727664878230021\n0.10710890091199447\n0.10694197623410572\n0.1067758672274896\n0.10661056647350171\n0.10644606665403081\n0.10628236054958191\n0.10611944103740954\n0.10595730108969803\n0.1057959337717887\n0.10563533224045142\n0.10547548974219983\n0.10531639961164839\n0.10515805526991034\n0.10500045022303518\n0.10484357806048421\n0.10468743245364344\n0.10453200715437223\n0.10437729599358714\n0.1042232928798791\n0.10406999179816386\n0.10391738680836429\n0.10376547204412281\n0.10361424171154479\n0.10346369008797061\n0.10331381152077526\n0.10316460042619681\n0.10301605128819005\n0.10286815865730668\n0.1027209171496005\n0.10257432144555668\n0.10242836628904531\n0.10228304648629694\n0.10213835690490158\n0.10199429247282861\n0.10185084817746808\n0.10170801906469241\n0.10156580023793842\n0.10142418685730815\n0.10128317413868897\n0.10114275735289202\n0.10100293182480811\n0.10086369293258164\n0.10072503610680084\n0.10058695682970477\n0.10044945063440618\n0.10031251310413007\n0.10017613987146753\n0.1000403266176439\n0.09990506907180208\n"
    }
   ],
   "source": [
    "import Models.logisticRegression as lr\n",
    "\n",
    "ionslr1 = lr.Logistic_Regression(0.02,\"Ionosphere\",\"binary\") # input step size\n",
    "# params = ionslr1.fit(cv_train_data, cv_train_label, 0.02, 1e-1)\n",
    "params1 = ionslr1.fit(training_data_ion,training_labels_ion,0.02,1e-1)\n",
    "#adding a separate comment\n",
    "# input learning rate and termination conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}