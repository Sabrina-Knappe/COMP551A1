{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit16c59f3069ba44c59fdc0e453d119bc5",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1  0  0.99539  -0.05889  0.85243  0.02306  0.83398  -0.37708      1.1  \\\n0    1  0  1.00000  -0.18829  0.93035 -0.36156 -0.10868  -0.93597  1.00000   \n1    1  0  1.00000  -0.03365  1.00000  0.00485  1.00000  -0.12062  0.88965   \n2    1  0  1.00000  -0.45161  1.00000  1.00000  0.71216  -1.00000  0.00000   \n3    1  0  1.00000  -0.02401  0.94140  0.06531  0.92106  -0.23255  0.77152   \n4    1  0  0.02337  -0.00592 -0.09924 -0.11949 -0.00763  -0.11824  0.14706   \n5    1  0  0.97588  -0.10602  0.94601 -0.20800  0.92806  -0.28350  0.85996   \n6    0  0  0.00000   0.00000  0.00000  0.00000  1.00000  -1.00000  0.00000   \n7    1  0  0.96355  -0.07198  1.00000 -0.14333  1.00000  -0.21313  1.00000   \n8    1  0 -0.01864  -0.08459  0.00000  0.00000  0.00000   0.00000  0.11470   \n9    1  0  1.00000   0.06655  1.00000 -0.18388  1.00000  -0.27320  1.00000   \n10   1  0  1.00000  -0.54210  1.00000 -1.00000  1.00000  -1.00000  1.00000   \n11   1  0  1.00000  -0.16316  1.00000 -0.10169  0.99999  -0.15197  1.00000   \n12   1  0  1.00000  -0.86701  1.00000  0.22280  0.85492  -0.39896  1.00000   \n13   1  0  1.00000   0.07380  1.00000  0.03420  1.00000  -0.05563  1.00000   \n14   1  0  0.50932  -0.93996  1.00000  0.26708 -0.03520  -1.00000  1.00000   \n15   1  0  0.99645   0.06468  1.00000 -0.01236  0.97811   0.02498  0.96112   \n16   0  0  0.00000   0.00000 -1.00000 -1.00000  1.00000   1.00000 -1.00000   \n17   1  0  0.67065   0.02528  0.66626  0.05031  0.57197   0.18761  0.08776   \n18   0  0  1.00000  -1.00000  0.00000  0.00000  0.00000   0.00000  1.00000   \n19   1  0  1.00000  -0.00612  1.00000 -0.09834  1.00000  -0.07649  1.00000   \n20   0  0  1.00000   1.00000  0.00000  0.00000  0.00000   0.00000 -1.00000   \n21   1  0  0.96071   0.07088  1.00000  0.04296  1.00000   0.09313  0.90169   \n22   0  0 -1.00000   1.00000  0.00000  0.00000  0.00000   0.00000 -1.00000   \n23   1  0  1.00000  -0.06182  1.00000  0.02942  1.00000  -0.05131  1.00000   \n24   1  0  1.00000   0.57820  1.00000 -1.00000  1.00000  -1.00000  1.00000   \n25   1  0  1.00000  -0.08714  1.00000 -0.17263  0.86635  -0.81779  0.94817   \n26   0  0 -1.00000  -1.00000  0.00000  0.00000 -1.00000   1.00000  1.00000   \n27   1  0  1.00000   0.08380  1.00000  0.17387  1.00000  -0.13308  0.98172   \n28   0  0 -1.00000  -1.00000  1.00000  1.00000  1.00000  -1.00000 -1.00000   \n29   1  0  1.00000  -0.14236  1.00000 -0.16256  1.00000  -0.23656  1.00000   \n..  .. ..      ...       ...      ...      ...      ...       ...      ...   \n320  1  0  0.89505  -0.03168  0.87525  0.05545  0.89505   0.01386  0.92871   \n321  1  0  0.90071   0.01773  1.00000 -0.01773  0.90071   0.00709  0.84752   \n322  1  0  0.39394  -0.24242  0.62655  0.01270  0.45455   0.09091  0.63636   \n323  1  0  0.86689   0.35950  0.72014  0.66667  0.37201   0.83049  0.08646   \n324  1  0  0.89563   0.37917  0.67311  0.69438  0.35916   0.88696 -0.04193   \n325  1  0  0.90547   0.41113  0.65354  0.74761  0.29921   0.95905 -0.13342   \n326  1  0  1.00000   1.00000  0.36700  0.06158  0.12993   0.92713 -0.27586   \n327  1  0  1.00000   0.51515  0.45455  0.33333  0.06061   0.36364 -0.32104   \n328  1  0  0.88110   0.00000  0.94817 -0.02744  0.93598  -0.01220  0.90244   \n329  1  0  0.82624   0.08156  0.79078 -0.08156  0.90426  -0.01773  0.92908   \n330  1  0  0.74468   0.10638  0.88706  0.00982  0.88542   0.01471  0.87234   \n331  1  0  0.87578   0.03727  0.89951  0.00343  0.89210   0.00510  0.86335   \n332  1  0  0.97513   0.00710  0.98579  0.01954  1.00000   0.01954  0.99290   \n333  1  0  1.00000   0.01105  1.00000  0.01105  1.00000   0.02320  0.99448   \n334  1  0  1.00000  -0.01342  1.00000  0.01566  1.00000  -0.00224  1.00000   \n335  1  0  0.88420   0.36724  0.67123  0.67382  0.39613   0.86399  0.02424   \n336  1  0  0.90147   0.41786  0.64131  0.75725  0.30440   0.95148 -0.20449   \n337  1  0  0.32789   0.11042  0.15970  0.29308  0.14020   0.74485 -0.25131   \n338  1  0  0.65845   0.43617  0.44681  0.74804  0.05319   0.85106 -0.32027   \n339  1  0  0.19466   0.05725  0.04198  0.25191 -0.10557   0.48866 -0.18321   \n340  1  0  0.98002   0.00075  1.00000  0.00000  0.98982  -0.00075  0.94721   \n341  1  0  0.82254  -0.07572  0.80462  0.00231  0.87514  -0.01214  0.86821   \n342  1  0  0.35346  -0.13768  0.69387 -0.02423  0.68195  -0.03574  0.55717   \n343  1  0  0.76046   0.01092  0.86335  0.00258  0.85821   0.00384  0.79988   \n344  1  0  0.66667  -0.01366  0.97404  0.06831  0.49590   0.50137  0.75683   \n345  1  0  0.83508   0.08298  0.73739 -0.14706  0.84349  -0.05567  0.90441   \n346  1  0  0.95113   0.00419  0.95183 -0.02723  0.93438  -0.01920  0.94590   \n347  1  0  0.94701  -0.00034  0.93207 -0.03227  0.95177  -0.03431  0.95584   \n348  1  0  0.90608  -0.01657  0.98122 -0.01989  0.95691  -0.03646  0.85746   \n349  1  0  0.84710   0.13533  0.73638 -0.06151  0.87873   0.08260  0.88928   \n\n     0.03760  ...  -0.51171  0.41078  -0.46168  0.21266  -0.34090  0.42267  \\\n0   -0.04549  ...  -0.26569 -0.20468  -0.18401 -0.19040  -0.11593 -0.16626   \n1    0.01198  ...  -0.40220  0.58984  -0.22145  0.43100  -0.17365  0.60436   \n2    0.00000  ...   0.90695  0.51613   1.00000  1.00000  -0.20099  0.25682   \n3   -0.16399  ...  -0.65158  0.13290  -0.53206  0.02431  -0.62197 -0.05707   \n4    0.06637  ...  -0.01535 -0.03240   0.09223 -0.07859   0.00732  0.00000   \n5   -0.27342  ...  -0.81634  0.13659  -0.82510  0.04606  -0.82395 -0.04262   \n6    0.00000  ...   1.00000  1.00000   1.00000  0.00000   0.00000  1.00000   \n7   -0.36174  ...  -0.65440  0.57577  -0.69712  0.25435  -0.63919  0.45114   \n8   -0.26810  ...  -0.01326  0.20645  -0.02294  0.00000   0.00000  0.16595   \n9   -0.43107  ...  -0.89128  0.47211  -0.86500  0.40303  -0.83675  0.30996   \n10   0.36217  ...  -0.40888  1.00000  -0.62745  1.00000  -1.00000  1.00000   \n11  -0.19277  ...  -0.47137  0.76224  -0.58370  0.65723  -0.68794  0.68714   \n12  -0.12090  ...  -0.17012  1.00000   0.35924  1.00000  -0.66494  1.00000   \n13   0.08764  ...   0.20033  1.00000   0.36743  0.95603   0.48641  1.00000   \n14  -1.00000  ...   0.92236  0.39752   0.26501  0.00000   0.00000  1.00000   \n15   0.02312  ...   0.13412  0.79476   0.13638  0.79110   0.15379  0.77122   \n16   1.00000  ...   1.00000  1.00000  -1.00000 -1.00000   1.00000 -1.00000   \n17   0.34081  ...   0.23724  0.46167   0.24618  0.43433   0.25306  0.40663   \n18   1.00000  ...   1.00000  1.00000   1.00000  1.00000  -1.00000  1.00000   \n19  -0.10605  ...  -0.40372  0.82681  -0.42231  0.75784  -0.38231  0.80448   \n20  -1.00000  ...   0.00000  1.00000  -1.00000 -1.00000   1.00000 -1.00000   \n21  -0.05144  ...  -0.07705  0.58051  -0.02205  0.49664  -0.01251  0.51310   \n22   1.00000  ...  -1.00000  1.00000  -1.00000  1.00000   1.00000 -1.00000   \n23  -0.01707  ...  -0.34838  0.72529  -0.29174  0.73094  -0.38576  0.54356   \n24  -1.00000  ...  -1.00000  1.00000  -1.00000  1.00000  -1.00000  1.00000   \n25   0.61053  ...  -0.82868  0.48136  -0.86583  0.40650  -0.89674  0.32984   \n26  -0.37500  ...  -1.00000 -1.00000   1.00000 -1.00000  -1.00000  0.00000   \n27   0.64520  ...   1.00000  0.83899   1.00000  0.74822   1.00000  0.64358   \n28   1.00000  ...   1.00000  1.00000  -1.00000  1.00000  -1.00000 -1.00000   \n29  -0.07514  ...  -0.47643  0.98820  -0.49687  1.00000  -0.75820  1.00000   \n..       ...  ...       ...      ...       ...      ...       ...      ...   \n320  0.02772  ...   0.02376  0.89002   0.01611  0.88119   0.00198  0.87327   \n321  0.05674  ...   0.04610  0.94305   0.03247  0.94681   0.02482  1.00000   \n322  0.09091  ...   0.05929  0.46362   0.06142  0.33333  -0.03030  0.41856   \n323  0.85893  ...  -0.59954  0.15360  -0.53127  0.32309  -0.37088  0.46189   \n324  0.93345  ...  -0.73856  0.33531  -0.62296  0.52414  -0.42086  0.61217   \n325  0.97820  ...  -0.85368  0.67538  -0.61959  0.85977  -0.28123  0.88654   \n326  0.93596  ...  -0.45950  0.85471  -0.06831  1.00000   1.00000  0.38670   \n327  0.73062  ...  -0.39394  0.72961   0.12331  0.96970   0.57576  0.24242   \n328  0.01829  ...   0.04878  0.89666   0.02226  0.90854   0.00915  1.00000   \n329  0.01064  ...   0.15957  0.89527   0.08165  0.77660   0.06738  0.92553   \n330 -0.01418  ...   0.11348  0.83429   0.06014  0.74468  -0.03546  0.81710   \n331  0.00000  ...  -0.04348  0.82111   0.02033  0.81988   0.08696  0.80757   \n332  0.01599  ...   0.03552  0.97540   0.06477  0.94849   0.08171  0.99112   \n333 -0.01436  ...  -0.00663  0.98033   0.01600  0.97901   0.01547  0.98564   \n334  0.06264  ...   0.10067  0.99989   0.08763  0.99105   0.08501  1.00000   \n335  0.93182  ...  -0.69774  0.26028  -0.60678  0.44569  -0.43383  0.54209   \n336  0.96534  ...  -0.82154  0.74105  -0.55231  0.89415  -0.18725  0.87893   \n337  0.91993  ...  -0.18560  0.39599  -0.11498  0.31005   0.05614  0.21443   \n338  0.82139  ...  -0.18645  0.74758   0.23713  0.45185   0.59071  0.20549   \n339 -0.18321  ...   0.24692  0.03913   0.31092 -0.03817   0.26336 -0.16794   \n340  0.02394  ...   0.08107  0.96709   0.07255  0.95701   0.08088  0.98190   \n341 -0.07514  ...  -0.02370  0.76717  -0.02731  0.74046  -0.07630  0.70058   \n342 -0.06119  ...  -0.00564  0.39146  -0.09038  0.35588  -0.10306  0.32232   \n343  0.02304  ...  -0.00303  0.70886   0.01375  0.66161   0.00849  0.66298   \n344 -0.00273  ...   0.06967  0.68656   0.17088  0.87568   0.07787  0.55328   \n345 -0.04622  ...  -0.04202  0.83479   0.00123  1.00000   0.12815  0.86660   \n346  0.01606  ...   0.01361  0.93522   0.04925  0.93159   0.08168  0.94066   \n347  0.02446  ...   0.03193  0.92489   0.02542  0.92120   0.02242  0.92459   \n348  0.00110  ...  -0.02099  0.89147  -0.07760  0.82983  -0.17238  0.96022   \n349 -0.09139  ...  -0.15114  0.81147  -0.04822  0.78207  -0.00703  0.75747   \n\n     -0.54487  0.18641  -0.45300  g  \n0    -0.06288 -0.13738  -0.02447  b  \n1    -0.24180  0.56045  -0.38238  g  \n2     1.00000 -0.32382   1.00000  b  \n3    -0.59573 -0.04608  -0.65697  g  \n4     0.00000 -0.00039   0.12011  b  \n5    -0.81318 -0.13832  -0.80975  g  \n6     1.00000  0.00000   0.00000  b  \n7    -0.72779  0.38895  -0.73420  g  \n8     0.24086 -0.08208   0.38065  b  \n9    -0.89093  0.22995  -0.89158  g  \n10   -1.00000  1.00000  -1.00000  b  \n11   -0.64537  0.64727  -0.67226  g  \n12    0.88428  1.00000  -0.18826  b  \n13    0.32492  1.00000   0.46712  g  \n14    0.23188  0.00000   0.00000  b  \n15    0.15930  0.70941   0.12015  g  \n16   -1.00000  1.00000  -1.00000  b  \n17    0.25792  1.00000   0.33036  g  \n18    1.00000  1.00000   1.00000  b  \n19   -0.40575  0.74354  -0.45039  g  \n20    1.00000 -1.00000   1.00000  b  \n21   -0.00015  0.52099  -0.00182  g  \n22    1.00000  0.00000   0.00000  b  \n23   -0.26284  0.64207  -0.39487  g  \n24   -1.00000  1.00000  -1.00000  b  \n25   -0.92128 -0.13341  -1.00000  g  \n26    0.00000 -1.00000   1.00000  b  \n27    1.00000  0.52479   1.00000  g  \n28    1.00000  1.00000  -1.00000  b  \n29   -0.75761  1.00000  -0.84437  g  \n..        ...      ...       ... ..  \n320   0.04158  0.86733   0.02376  g  \n321   0.01064  0.93617   0.02128  g  \n322   0.06410  0.39394   0.24242  g  \n323  -0.19681  0.40956   0.01820  g  \n324  -0.17343  0.60073   0.08660  g  \n325   0.09800  0.75495   0.46301  g  \n326   0.00246  0.17758   0.79790  g  \n327   0.36364  0.09091   0.33333  g  \n328   0.05488  0.97561  -0.01220  g  \n329   0.18085  0.92553   0.00000  g  \n330   0.06800  0.80774   0.07173  g  \n331   0.02308  0.80088   0.02441  g  \n332   0.06217  0.98934   0.09947  g  \n333   0.02099  0.98674   0.02762  g  \n334   0.10067  1.00000   0.10067  g  \n335  -0.21542  0.56286   0.02823  g  \n336   0.20359  0.70555   0.54852  g  \n337   0.20540  0.13376   0.26422  g  \n338   0.76764 -0.18533   0.74356  g  \n339   0.16794 -0.30153  -0.33588  g  \n340   0.08126  0.97247   0.08616  g  \n341  -0.04220  0.78439   0.01214  g  \n342  -0.08637  0.28943  -0.08300  g  \n343   0.01484  0.63887   0.01525  g  \n344   0.24590  0.13934   0.48087  g  \n345  -0.10714  0.90546  -0.04307  g  \n346  -0.00035  0.91483   0.04712  g  \n347   0.00442  0.92697  -0.00577  g  \n348  -0.03757  0.87403  -0.16243  g  \n349  -0.06678  0.85764  -0.06151  g  \n\n[350 rows x 35 columns]\n"
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'ionosphere-data.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('ionosphere-data.csv', sep=',')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g'\n 'b' 'g' 'b' 'g' 'b' 'g' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b' 'g' 'b'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g'\n 'g' 'g' 'g' 'g' 'g' 'g' 'g' 'g']\n"
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Convert to numpy\n",
    "#df.to_numpy()\n",
    "temp = df.values\n",
    "R,C = temp.shape\n",
    "#print(C)\n",
    "\n",
    "# Split array into design matrix and labels\n",
    "ionosphere_labels = temp[:, C-1]\n",
    "print(ionosphere_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1 0 1.0 ... -0.06287999999999999 -0.13738 -0.02447]\n [1 0 1.0 ... -0.2418 0.56045 -0.38238]\n [1 0 1.0 ... 1.0 -0.32382 1.0]\n ...\n [1 0 0.94701 ... 0.00442 0.9269700000000001 -0.00577]\n [1 0 0.9060799999999999 ... -0.03757 0.87403 -0.16243]\n [1 0 0.8471 ... -0.06677999999999999 0.85764 -0.06151]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Remove labels to get design matrix\n",
    "ionosphere_design_matrix= np.delete(temp, C-1, 1)\n",
    "print(ionosphere_design_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1\n 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1\n 1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0\n 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1\n 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 1\n 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0\n 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1]\n[0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1\n 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1]\n"
    }
   ],
   "source": [
    "import Models.kfold_CV_try as cv\n",
    "\n",
    "# Train test split\n",
    "xTrain_ion, xTest_ion, yTrain_ion, yTest_ion = cv.split_train_test(ionosphere_design_matrix, ionosphere_labels, 0.2)\n",
    "# print(xTest_ion); print(xTrain_ion); print(yTest_ion);print(yTrain_ion)\n",
    "# change the binary label 'g' and 'b' into 1 and 0\n",
    "for i in enumerate(yTrain_ion):\n",
    "    if i[1] == 'g':\n",
    "        yTrain_ion[i[0]] = 1\n",
    "    elif i[1] == 'b':\n",
    "        yTrain_ion[i[0]] = 0\n",
    "yTrain_ion=yTrain_ion.astype('int')\n",
    "for i in enumerate(yTest_ion):\n",
    "    if i[1] == 'g':\n",
    "        yTest_ion[i[0]] = 1\n",
    "    elif i[1] == 'b':\n",
    "        yTest_ion[i[0]] = 0        \n",
    "yTest_ion=yTest_ion.astype('int')\n",
    "\n",
    "print(yTrain_ion);print(yTest_ion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1 0 0.6351 ... 0.19841 0.69053 0.36721]\n [1 0 0.31034 ... -0.00011999999999999999 -8e-05 -5.9999999999999995e-05]\n [1 0 0.5984 ... 0.81007 0.81979 0.6882199999999999]\n ...\n [1 0 0.0 ... 1.0 0.0 0.0]\n [1 0 1.0 ... 1.0 -1.0 1.0]\n [1 0 0.5 ... 0.14783 0.44783 0.17390999999999998]] [1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1\n 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 1]\n(56, 34) (56,)\n"
    }
   ],
   "source": [
    "folds = 5 # delete folds later when embedded in function input\n",
    "# cv_train_data_ion is xTrain_ion split into five chunks\n",
    "dataset_split_in, cv_train_data_ion,cv_train_label_ion= cv.kfold_cross_validation(xTrain_ion,yTrain_ion,folds)\n",
    "# print(cv_train_data_ion,cv_train_label_ion)\n",
    "\n",
    "# the last input for cv.train_validation_split is the number of experiments you are running currently, 5 in total. \n",
    "# each experiments is organizing the five chunks from cv_train_data_ion into 4 chunks for training_data_ion and 1 chunk for validate_data_ion for cross validation, just need to uncomment the line you want to experiment currently. \n",
    "\n",
    "# will be in a for-loop when computing accuracy scores \n",
    "#exp1: \n",
    "validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,1)\n",
    "\n",
    "#exp2:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,2)\n",
    "\n",
    "#exp3:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,3)\n",
    "\n",
    "#exp4:\n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,4)\n",
    "\n",
    "#exp5: \n",
    "#validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,5)\n",
    "print(validate_data_ion,validate_labels_ion)\n",
    "print(validate_data_ion.shape,validate_labels_ion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Now fitting Ionosphere\n0.5912739580935384\n0.5758787500880542\n0.5610043835223915\n0.546642430428586\n0.5327830586228288\n0.5194152831105053\n0.5065271931510879\n0.4941061553866964\n0.48213899392048576\n0.47061214857400224\n0.4595118127794129\n0.44882405269490444\n0.43853490918932336\n0.4286304843426618\n0.4190970140670121\n0.409920928380467\n0.40108890077406384\n0.3925878880072637\n0.38440516155671545\n0.37652833183088913\n0.3689453661529638\n0.3616446014085338\n0.3546147521548654\n0.34784491489558234\n0.3413245691392797\n0.33504357578283417\n0.3289921732899744\n0.3231609720727332\n0.3175409474273084\n0.31212343132615405\n0.30690010332428974\n0.3018629807993263\n0.29700440871106537\n0.2923170490372254\n0.2877938700164056\n0.2834281353074151\n0.2792133931551255\n0.2751434656367207\n0.27121243804827094\n0.267414648479648\n0.26374467761568654\n0.2601973387929064\n0.2567676683338811\n0.25345091617524707\n0.25024253680026154\n0.2471381804825815\n0.24413368484443107\n0.24122506672945151\n0.23840851438817795\n0.2356803799722041\n0.2330371723315804\n0.23047555010881682\n0.22799231512194462\n0.2255844060284198\n0.22324889226115308\n0.22098296822762822\n0.2187839477628697\n0.21664925882693084\n0.21457643843757143\n0.21256312782886497\n0.21060706782660057\n0.20870609443151816\n0.20685813460162045\n0.20506120222504087\n0.20331339427520007\n0.201612887140247\n0.19995793311906146\n0.19834685707637245\n0.19677805324983175\n0.1952499822021607\n0.19376116791177284\n0.19231019499554314\n0.19089570605766795\n0.18951639915882007\n0.18817102540005679\n0.18685838661618484\n0.1855773331735276\n0.18432676186726266\n0.18310561391372449\n0.1819128730332739\n0.1807475636195418\n0.1796087489910485\n0.17849552972138497\n0.17740704204432098\n0.17634245633037665\n0.1753009756315529\n0.17428183429107408\n0.17328429661514375\n0.17230765560385336\n0.1713512317385205\n0.17041437182285996\n0.16949644787551466\n0.16859685607158656\n0.16771501573092246\n0.1668503683510132\n0.16600237668246406\n0.1651705238450934\n0.16435431248280355\n0.1635532639554596\n0.1627669175660897\n0.1619948298218027\n0.16123657372689293\n0.1604917381066725\n0.1597599269606418\n0.15904075884367072\n0.1583338662739271\n0.15763889516634852\n0.15695550429050478\n0.15628336475175916\n0.15562215949468008\n0.1549715828277082\n0.15433133996812862\n0.1537011466064393\n0.15308072848925483\n0.15246982101991657\n0.1518681688760252\n0.15127552564314362\n0.1506916534639548\n0.15011632270219072\n0.14954931162068055\n0.14899040607289646\n0.14843939920740293\n0.14789609118464278\n0.14736028890552022\n0.14683180575126392\n0.1463104613340772\n0.14579608125810703\n0.14528849689028017\n0.1447875451405801\n0.14429306825135496\n0.14380491359526482\n0.14332293348149666\n0.14284698496988957\n0.1423769296926309\n0.14191263368319726\n0.1414539672122308\n0.1410008046300538\n0.14055302421553828\n0.14011050803106018\n0.13967314178327908\n0.13924081468949626\n0.1388134193493558\n0.1383908516216617\n0.1379730105060964\n0.13755979802963328\n0.13715111913744757\n0.13674688158813558\n0.13634699585306284\n0.13595137501966906\n0.1355599346985641\n0.135172592934259\n0.1347892701193794\n0.13440988891221844\n0.13403437415749134\n0.1336626528101583\n0.13329465386219125\n0.13293030827216262\n0.13256954889754008\n0.13221231042957823\n0.1318585293306994\n0.1315081437742637\n0.1311610935866305\n0.13081732019141884\n0.13047676655587728\n0.13013937713927842\n0.1298050978432572\n0.12947387596401283\n0.12914566014630233\n0.12882040033915101\n0.128498047753214\n0.1281785548197215\n0.127861875150944\n0.12754796350212003\n0.1272367757347849\n0.12692826878144772\n0.12662240061156213\n0.12631913019874058\n0.12601841748916257\n0.1257202233711305\n0.12542450964572827\n0.12513123899853942\n0.1248403749723833\n0.12455188194103012\n0.12426572508385678\n0.12398187036140676\n0.12370028449181938\n0.1234209349280953\n0.12314378983616477\n0.12286881807372964\n0.12259598916984797\n0.12232527330523363\n0.12205664129324326\n0.12179006456152457\n0.1215255151343012\n0.12126296561526886\n0.12100238917108125\n0.12074375951540205\n0.12048705089350262\n0.12023223806738405\n0.11997929630140519\n0.11972820134839601\n0.11947892943623972\n0.11923145725490496\n0.11898576194391254\n0.11874182108021954\n0.11849961266650555\n0.1182591151198471\n0.11802030726076439\n0.11778316830262837\n0.11754767784141326\n0.11731381584578356\n0.11708156264750152\n0.11685089893214529\n0.11662180573012497\n0.11639426440798634\n0.11616825665999217\n0.11594376449997033\n0.11572077025341995\n0.11549925654986562\n0.11527920631545148\n0.11506060276576562\n0.11484342939888798\n0.11462766998865227\n0.11441330857811563\n0.11420032947322782\n0.11398871723669352\n0.11377845668202015\n0.11356953286774593\n0.11336193109184031\n0.11315563688627245\n0.11295063601174034\n0.11274691445255615\n0.11254445841168188\n0.11234325430591002\n0.11214328876118461\n0.11194454860805786\n0.11174702087727709\n0.11155069279549834\n0.11135555178112215\n0.11116158544024675\n0.11096878156273558\n0.1107771281183949\n0.11058661325325753\n0.11039722528596975\n0.11020895270427743\n0.1100217841616081\n0.10983570847374681\n0.10965071461560053\n0.10946679171805077\n0.10928392906488933\n0.1091021160898362\n0.10892134237363528\n0.10874159764122719\n0.10856287175899504\n0.10838515473208166\n0.10820843670177648\n0.10803270794296839\n0.10785795886166391\n0.1076841799925679\n0.10751136199672481\n0.1073394956592189\n0.10716857188693155\n0.10699858170635337\n0.10682951626145024\n0.10666136681158067\n0.10649412472946414\n0.10632778149919743\n0.10616232871431854\n0.10599775807591638\n0.10583406139078477\n0.10567123056961976\n0.10550925762525831\n0.10534813467095816\n0.10518785391871645\n0.10502840767762683\n0.10486978835227379\n0.10471198844116257\n0.10455500053518443\n0.10439881731611583\n0.1042434315551502\n0.1040888361114622\n0.10393502393080283\n0.10378198804412504\n0.10362972156623836\n0.10347821769449253\n0.10332746970748838\n0.10317747096381637\n0.10302821490082098\n0.10287969503339059\n0.1027319049527725\n0.10258483832541192\n0.10243848889181471\n0.10229285046543266\n0.10214791693157158\n0.1020036822463205\n0.10186014043550257\n0.10171728559364614\n0.10157511188297623\n0.10143361353242517\n0.10129278483666249\n0.10115262015514342\n0.10101311391117536\n0.10087426059100182\n0.10073605474290405\n0.10059849097631873\n0.10046156396097254\n0.10032526842603257\n0.10018959915927196\n0.10005455100625127\n0.09992011886951398\n"
    }
   ],
   "source": [
    "import Models.logisticRegression as lr\n",
    "\n",
    "ionslr1 = lr.Logistic_Regression(0.02,\"Ionosphere\",\"binary\") # input step size\n",
    "# params = ionslr1.fit(cv_train_data, cv_train_label, 0.02, 1e-1)\n",
    "params1 = ionslr1.fit(training_data_ion,training_labels_ion,0.02,1e-1)\n",
    "#adding a separate comment\n",
    "# input learning rate and termination conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1]\n[1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1\n 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 1]\n"
    }
   ],
   "source": [
    "# %% Making LR prediction on the validatoin set\n",
    "\n",
    "# need to convert predictions into 1 or 0\n",
    "\n",
    "# pred_vali1 is a boolean array, pred_vali*1 gives binary 1 or 0 automatically \n",
    "pred_vali = ionslr1.predict(params1,validate_data_ion)\n",
    "pred_vali=pred_vali * 1\n",
    "\n",
    "print(pred_vali)\n",
    "print(validate_labels_ion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1\n 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n"
    }
   ],
   "source": [
    "# try prediction for testing set \n",
    "# print(xTest_ion); print(yTest_ion)\n",
    "pred_test = ionslr1.predict(params1,xTest_ion)\n",
    "# change boolean into 1 or 0\n",
    "pred_test = pred_test * 1\n",
    "print(pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0137\n0.10700368284348377\n0.10679756754012915\n0.10659232012436075\n0.10638793587738854\n0.10618441011123934\n0.10598173816848974\n0.10577991542200252\n0.10557893727466613\n0.1053787991591374\n0.105179496537587\n0.10498102490144814\n0.1047833797711682\n0.10458655669596324\n0.10439055125357548\n0.1041953590500335\n0.10400097571941529\n0.10380739692361414\n0.10361461835210724\n0.10342263572172651\n0.10323144477643313\n0.10304104128709352\n0.1028514210512585\n0.102662579892945\n0.1024745136624201\n0.10228721823598737\n0.10210068951577621\n0.10191492342953294\n0.10172991593041468\n0.10154566299678526\n0.10136216063201367\n0.10117940486427468\n0.10099739174635167\n0.10081611735544152\n0.1006355777929621\n0.10045576918436123\n0.10027668767892856\n0.10009832944960861\n0.09992069069281681\nNow fitting Ionosphere\n0.21517903452825093\n0.21440401599672468\n0.21363394445687092\n0.2128687810457747\n0.2121084871362315\n0.21135302433950606\n0.2106023545079146\n0.2098564397372342\n0.20911524236894524\n0.20837872499231153\n0.2076468504463046\n0.20691958182137432\n0.20619688246107395\n0.20547871596354178\n0.2047650461828447\n0.20405583723018902\n0.2033510534750019\n0.20265065954588704\n0.20195462033146108\n0.20126290098107288\n0.20057546690540912\n0.19989228377699256\n0.19921331753057425\n0.19853853436342483\n0.19786790073552754\n0.19720138336967705\n0.19653894925148785\n0.1958805656293138\n0.19522620001408483\n0.19457582017906033\n0.19392939415950658\n0.19328689025229678\n0.19264827701544057\n0.19201352326754156\n0.1913825980871913\n0.19075547081229588\n0.19013211103934302\n0.18951248862260928\n0.1888965736733107\n0.1882843365586993\n0.187675747901108\n0.187070778576945\n0.18646939971564186\n0.18587158269855517\n0.18527729915782568\n0.18468652097519594\n0.18409922028078796\n0.18351536945184485\n0.18293494111143532\n0.18235790812712546\n0.18178424360961815\n0.18121392091136115\n0.18064691362512847\n0.18008319558257183\n0.17952274085274894\n0.17896552374062583\n0.17841151878555744\n0.1778607007597463\n0.17731304466668119\n0.17676852573955776\n0.17622711943968042\n0.17568880145484944\n0.17515354769773206\n0.17462133430421994\n0.1740921376317739\n0.17356593425775693\n0.17304270097775643\n0.17252241480389713\n0.17200505296314458\n0.1714905928956019\n0.17097901225279863\n0.17047028889597443\n0.16996440089435713\n0.16946132652343668\n0.16896104426323547\n0.16846353279657614\n0.1679687710073469\n0.1674767379787657\n0.16698741299164419\n0.1665007755226507\n0.16601680524257467\n0.16553548201459228\n0.16505678589253323\n0.1645806971191506\n0.16410719612439317\n0.1636362635236814\n0.16316788011618735\n0.16270202688311863\n0.16223868498600796\n0.16177783576500712\n0.16131946073718711\n0.16086354159484476\n0.16041006020381496\n0.1599589986017904\n0.15951033899664868\n0.1590640637647863\n0.15862015544946098\n0.15817859675914253\n0.15773937056587084\n0.15730245990362457\n0.1568678479666972\n0.156435518108083\n0.15600545383787262\n0.1555776388216583\n0.15515205687894876\n0.1547286919815944\n0.15430752825222313\n0.15388854996268628\n0.1534717415325151\n0.1530570875273887\n0.15264457265761233\n0.15223418177660702\n0.1518258998794105\n0.15141971210118949\n0.15101560371576328\n0.15061356013413915\n0.1502135669030591\n0.1498156097035586\n0.1494196743495373\n0.14902574678634103\n0.14863381308935658\n0.1482438594626177\n0.1478558722374238\n0.14746983787097026\n0.14708574294499135\n0.1467035741644149\n0.14632331835602927\n0.14594496246716296\n0.1455684935643758\n0.14519389883216263\n0.14482116557166977\n0.1444502811994225\n0.144081233246066\n0.14371400935511805\n0.14334859728173363\n0.14298498489148212\n0.14262316015913667\n0.1422631111674753\n0.14190482610609478\n0.14154829327023585\n0.14119350105962086\n0.1408404379773036\n0.1404890926285308\n0.14013945371961517\n0.13979151005682167\n0.13944525054526352\n0.13910066418781195\n0.13875774008401645\n0.1384164674290369\n0.13807683551258765\n0.13773883371789275\n0.13740245152065234\n0.1370676784880214\n0.13673450427759873\n0.13640291863642792\n0.13607291140000902\n0.13574447249132163\n0.13541759191985855\n0.13509225978067133\n0.13476846625342515\n0.1344462016014662\n0.13412545617089836\n0.13380622038967122\n0.1334884847666787\n0.1331722398908675\n0.13285747643035664\n0.13254418513156682\n0.1322323568183601\n0.13192198239118982\n0.13161305282626026\n0.13130555917469666\n0.1309994925617246\n0.13069484418585942\n0.13039160531810534\n0.13008976730116412\n0.12978932154865302\n0.12949025954433244\n0.12919257284134283\n0.12889625306145047\n0.12860129189430292\n0.12830768109669305\n0.12801541249183254\n0.1277244779686336\n0.1274348694809998\n0.12714657904712573\n0.12685959874880498\n0.12657392073074686\n0.1262895371999011\n0.12600644042479153\n0.12572462273485738\n0.12544407651980305\n0.12516479422895593\n0.12488676837063212\n0.1246099915115097\n0.12433445627601072\n0.12406015534568984\n0.12378708145863111\n0.12351522740885237\n0.12324458604571695\n0.12297515027335233\n0.12270691305007699\n0.12243986738783376\n0.1221740063516301\n0.12190932305898623\n0.1216458106793895\n0.12138346243375578\n0.12112227159389778\n0.12086223148199987\n0.12060333547009966\n0.12034557697957622\n0.12008894948064415\n0.11983344649185501\n0.11957906157960398\n0.11932578835764386\n0.11907362048660398\n0.11882255167351626\n0.11857257567134662\n0.11832368627853254\n0.11807587733852645\n0.11782914273934486\n0.11758347641312293\n0.1173388723356754\n0.11709532452606203\n0.1168528270461595\n0.11661137400023795\n0.11637095953454347\n0.11613157783688541\n0.11589322313622896\n0.11565588970229333\n0.11541957184515422\n0.11518426391485186\n0.11494996030100389\n0.11471665543242296\n0.11448434377673919\n0.11425301984002742\n0.11402267816643911\n0.11379331333783889\n0.1135649199734455\n0.11333749272947753\n0.11311102629880336\n0.11288551541059537\n0.11266095482998884\n0.1124373393577448\n0.11221466382991709\n0.11199292311752379\n0.1117721121262225\n0.11155222579598968\n0.1113332591008042\n0.11111520704833439\n0.11089806467962944\n0.11068182706881417\n0.11046648932278788\n0.11025204658092685\n0.1100384940147903\n0.10982582682783004\n0.10961404025510416\n0.10940312956299338\n0.10919309004892146\n0.10898391704107885\n0.10877560589814975\n0.10856815200904237\n0.10836155079262275\n0.10815579769745126\n0.10795088820152306\n0.10774681781201088\n0.10754358206501158\n0.10734117652529523\n0.10713959678605768\n0.10693883846867569\n0.10673889722246509\n0.10653976872444214\n0.10634144867908722\n0.10614393281811182\n0.10594721690022768\n0.10575129671091954\n0.10555616806221967\n0.10536182679248568\n0.10516826876618053\n0.10497548987365546\n0.10478348603093536\n0.10459225317950621\n0.10440178728610593\n0.10421208434251658\n0.10402314036535971\n0.10383495139589398\n0.10364751349981466\n0.10346082276705601\n0.10327487531159554\n0.10308966727126068\n0.1029051948075375\n0.10272145410538193\n0.10253844137303263\n0.10235615284182646\n0.10217458476601562\n0.10199373342258725\n0.10181359511108469\n0.1016341661534309\n0.1014554428937539\n0.10127742169821405\n0.10110009895483334\n0.1009234710733262\n0.10074753448493307\n0.10057228564225446\n0.1003977210190883\n0.10022383711026776\n0.10005063043150177\n0.0998780975192166\nNow fitting Ionosphere\n0.21735616432106852\n0.21651289214707478\n0.21567626596509956\n0.2148462201578502\n0.21402268957257095\n0.21320560952912437\n0.21239491582749373\n0.2115905447547206\n0.21079243309130358\n0.21000051811707535\n0.20921473761657766\n0.20843502988395438\n0.20766133372738044\n0.20689358847304415\n0.2061317339687008\n0.2053757105868151\n0.2046254592273082\n0.2038809213199247\n0.20314203882623788\n0.2024087542413052\n0.20168101059498902\n0.20095875145296058\n0.20024192091739568\n0.19953046362737864\n0.19882432475902712\n0.19812345002534948\n0.197427785675848\n0.19673727849587747\n0.19605187580577402\n0.1953715254597614\n0.1946961758446481\n0.19402577587832417\n0.19336027500806763\n0.19269962320867148\n0.19204377098039813\n0.1913926693467726\n0.19074626985222104\n0.19010452455956445\n0.18946738604737481\n0.1888348074072013\n0.1882067422406737\n0.18758314465649203\n0.18696396926730613\n0.18634917118649433\n0.1857387060248475\n0.1851325298871625\n0.18453059936875352\n0.1839328715518849\n0.18333930400213247\n0.18274985476467748\n0.18216448236053936\n0.18158314578275\n0.1810058044924769\n0.18043241841509805\n0.17986294793623228\n0.17929735389773094\n0.1787355975936334\n0.17817764076609022\n0.1776234456012587\n0.17707297472517283\n0.176526191199592\n0.1759830585178305\n0.1754435406005726\n0.17490760179167383\n0.17437520685395327\n0.17384632096497843\n0.1733209097128446\n0.1727989390919527\n0.1722803754987867\n0.1717651857276934\n0.17125333696666534\n0.17074479679313123\n0.17023953316975338\n0.1697375144402351\n0.16923870932513946\n0.16874308691772139\n0.16825061667977362\n0.1677612684374896\n0.16727501237734277\n0.16679181904198523\n0.1663116593261653\n0.1658345044726672\n0.16536032606827225\n0.1648890960397425\n0.16442078664982981\n0.16395537049330847\n0.16349282049303482\n0.16303310989603204\n0.162576212269604\n0.1621221014974755\n0.16167075177596188\n0.1612221376101683\n0.16077623381021766\n0.16033301548751\n0.1598924580510118\n0.15945453720357733\n0.1590192289383005\n0.15858650953489992\n0.1581563555561351\n0.15772874384425606\n0.15730365151748563\n0.15688105596653415\n0.15646093485114876\n0.15604326609669475\n0.1556280278907716\n0.15521519867986205\n0.15480475716601558\n0.1543966823035656\n0.15399095329588025\n0.15358754959214782\n0.15318645088419625\n0.15278763710334606\n0.1523910884172979\n0.15199678522705387\n0.1516047081638729\n0.1512148380862598\n0.1508271560769889\n0.15044164344015998\n0.15005828169828941\n0.14967705258943365\n0.149297938064347\n0.14892092028367168\n0.14854598161516175\n0.1481731046309399\n0.14780227210478633\n0.14743346700946086\n0.14706667251405767\n0.14670187198139123\n0.14633904896541536\n0.14597818720867325\n0.14561927063977978\n0.14526228337093403\n0.14490720969546492\n0.14455403408540543\n0.1442027411890993\n0.1438533158288371\n0.143505742998523\n0.1431600078613715\n0.1428160957476333\n0.14247399215235118\n0.14213368273314483\n0.1417951533080246\n0.1414583898532338\n0.14112337850111953\n0.14079010553803165\n0.14045855740224897\n0.1401287206819345\n0.139800582113116\n0.13947412857769517\n0.13914934710148286\n0.1388262248522611\n0.13850474913787067\n0.1381849074043253\n0.13786668723395143\n0.13755007634355276\n0.13723506258260088\n0.1369216339314495\n0.13660977849957423\n0.13629948452383644\n0.13599074036677056\n0.13568353451489554\n0.13537785557705004\n0.13507369228275004\n0.13477103348056996\n0.13446986813654618\n0.13417018533260308\n0.13387197426500072\n0.13357522424280527\n0.13327992468637972\n0.13298606512589708\n0.13269363519987404\n0.1324026246537254\n0.1321130233383392\n0.13182482120867212\n0.13153800832236454\n0.13125257483837585\n0.13096851101563903\n0.13068580721173428\n0.13040445388158212\n0.13012444157615488\n0.12984576094120678\n0.1295684027160222\n0.12929235773218248\n0.12901761691234961\n0.12874417126906862\n0.128472011903586\n0.12820113000468647\n0.1279315168475457\n0.1276631637926002\n0.12739606228443315\n0.12713020385067714\n0.12686558010093196\n0.12660218272569895\n0.1263400034953303\n0.12607903425899428\n0.12581926694365472\n0.1255606935530663\n0.125303306166784\n0.12504709693918695\n0.124792058098517\n0.12453818194593116\n0.1242854608545677\n0.1240338872686262\n0.12378345370246116\n0.12353415273968853\n0.12328597703230594\n0.12303891929982523\n0.1227929723284179\n0.12254812897007376\n0.12230438214177086\n0.12206172482465841\n0.12182015006325138\n0.12157965096463719\n0.12134022069769367\n0.12110185249231924\n0.12086453963867327\n0.1206282754864289\n0.12039305344403611\n0.12015886697799553\n0.11992570961214342\n0.11969357492694686\n0.11946245655880953\n0.11923234819938731\n0.11900324359491436\n0.11877513654553895\n0.11854802090466894\n0.11832189057832711\n0.11809673952451578\n0.11787256175259082\n0.11764935132264498\n0.1174271023448999\n0.11720580897910766\n0.11698546543396043\n0.11676606596650914\n0.11654760488159085\n0.11633007653126395\n0.1161134753142523\n0.11589779567539678\n0.11568303210511556\n0.11546917913887182\n0.11525623135664911\n0.11504418338243523\n0.11483302988371236\n0.11462276557095565\n0.11441338519713848\n0.11420488355724567\n0.11399725548779256\n0.11379049586635244\n0.11358459961108967\n0.11337956168030063\n0.11317537707196011\n0.11297204082327553\n0.11276954801024655\n0.11256789374723175\n0.11236707318652125\n0.11216708151791538\n0.11196791396830981\n0.11176956580128602\n0.11157203231670856\n0.11137530885032704\n0.11117939077338453\n0.11098427349223153\n0.1107899524479451\n0.11059642311595345\n0.11040368100566637\n0.11021172166011038\n0.11002054065556924\n0.10983013360122978\n0.10964049613883242\n0.10945162394232653\n0.10926351271753133\n0.10907615820180085\n0.10888955616369388\n0.10870370240264848\n0.10851859274866166\n0.10833422306197205\n0.10815058923274898\n0.10796768718078421\n0.10778551285518893\n0.10760406223409447\n0.10742333132435772\n0.10724331616126985\n0.10706401280826984\n0.10688541735666131\n0.1067075259253337\n0.10653033466048727\n0.10635383973536139\n0.10617803734996709\n0.10600292373082308\n0.10582849513069527\n0.10565474782833989\n0.10548167812825017\n0.10530928236040632\n0.10513755688002908\n0.10496649806733632\n0.10479610232730316\n0.1046263660894252\n0.10445728580748481\n0.1042888579593208\n0.10412107904660096\n0.10395394559459768\n0.10378745415196652\n0.10362160129052778\n0.10345638360505068\n0.10329179771304099\n0.10312784025453062\n0.10296450789187067\n0.10280179730952695\n0.10263970521387762\n0.10247822833301469\n0.10231736341654667\n0.10215710723540493\n0.10199745658165159\n0.10183840826829092\n0.10167995912908212\n0.10152210601835505\n0.10136484581082829\n0.10120817540142943\n0.10105209170511747\n0.10089659165670785\n0.10074167221069912\n0.10058733034110247\n0.10043356304127271\n0.10028036732374179\n0.10012774022005427\n0.09997567878060484\nNow fitting Ionosphere\n0.22853044414926696\n0.22763420803043916\n0.22674472016776803\n0.22586191560248395\n0.2249857298697721\n0.22411609900446916\n0.22325295954627122\n0.22239624854447365\n0.22154590356225867\n0.22070186268054992\n0.21986406450145088\n0.21903244815128442\n0.21820695328324674\n0.2173875200796968\n0.21657408925408994\n0.21576660205257692\n0.21496500025527654\n0.21416922617724127\n0.2133792226691244\n0.21259493311756555\n0.21181630144530472\n0.21104327211103746\n0.21027579010902422\n0.20951380096846325\n0.20875725075263893\n0.20800608605785698\n0.20726025401217515\n0.20651970227394023\n0.20578437903014077\n0.20505423299458508\n0.2043292134059126\n0.20360927002544696\n0.20289435313490123\n0.20218441353394018\n0.20147940253760954\n0.20077927197363865\n0.2000839741796241\n0.19939346200010033\n0.1987076887835049\n0.1980266083790443\n0.19735017513346637\n0.19667834388774508\n0.19601106997368356\n0.19534830921044086\n0.19469001790098756\n0.19403615282849512\n0.19338667125266396\n0.19274153090599486\n0.19210068999000837\n0.19146410717141601\n0.1908317415782476\n0.19020355279593895\n0.18957950086338263\n0.18895954626894756\n0.1883436499464682\n0.18773177327120832\n0.1871238780558028\n0.18651992654617902\n0.18591988141746213\n0.18532370576986598\n0.18473136312457386\n0.18414281741960883\n0.18355803300569987\n0.18297697464214233\n0.18239960749265757\n0.18182589712125327\n0.18125580948808517\n0.18068931094532398\n0.18012636823302822\n0.17956694847502472\n0.17901101917479934\n0.1784585482113976\n0.1779095038353396\n0.17736385466454718\n0.1768215696802884\n0.17628261822313643\n0.17574696998894898\n0.17521459502486417\n0.17468546372531826\n0.17415954682808396\n0.17363681541033063\n0.17311724088470762\n0.1726007949954516\n0.17208744981451887\n0.17157717773774192\n0.17106995148101364\n0.17056574407649713\n0.17006452886886353\n0.16956627951155764\n0.16907096996309254\n0.16857857448337188\n0.16808906763004355\n0.16760242425488162\n0.1671186195001996\n0.1666376287952939\n0.16615942785291832\n0.16568399266579004\n0.1652112995031268\n0.16474132490721613\n0.16427404569001666\n0.16380943892979125\n0.1633474819677727\n0.1628881524048623\n0.16243142809836014\n0.16197728715872883\n0.16152570794638985\n0.16107666906855259\n0.1606301493760766\n0.1601861279603659\n0.15974458415029755\n0.15930549750918163\n0.15886884783175537\n0.15843461514120893\n0.1580027796862452\n0.15757332193817095\n0.1571462225880219\n0.1567214625437187\n0.1562990229272575\n0.15587888507193046\n0.1554610305195803\n0.15504544101788534\n0.15463209851767795\n0.15422098517029353\n0.1538120833249513\n0.15340537552616687\n0.1530008445111957\n0.15259847320750738\n0.15219824473029164\n0.15180014237999345\n0.15140414963987983\n0.15101025017363667\n0.15061842782299473\n0.1502286666053865\n0.1498409507116318\n0.14945526450365296\n0.14907159251221933\n0.14868991943472\n0.148310230132966\n0.1479325096310198\n0.14755674311305408\n0.14718291592123725\n0.14681101355364745\n0.14644102166221343\n0.14607292605068264\n0.14570671267261623\n0.14534236762941063\n0.14497987716834534\n0.14461922768065694\n0.14426040569963877\n0.14390339789876636\n0.1435481910898477\n0.14319477222119928\n0.14284312837584587\n0.142493246769746\n0.1421451147500403\n0.1417987197933251\n0.1414540495039487\n0.14111109161233193\n0.14076983397331114\n0.14043026456450433\n0.14009237148470047\n0.1397561429522704\n0.1394215673036\n0.13908863299154597\n0.1387573285839123\n0.1384276427619484\n0.13809956431886872\n0.13777308215839248\n0.1374481852933046\n0.1371248628440366\n0.13680310403726786\n0.13648289820454657\n0.13616423478092976\n0.13584710330364408\n0.13553149341076365\n0.13521739483990908\n0.1349047974269626\n0.1345936911048037\n0.13428406590206188\n0.13397591194188724\n0.13366921944073892\n0.13336397870719133\n0.1330601801407568\n0.1327578142307259\n0.132456871555024\n0.13215734277908495\n0.13185921865474023\n0.13156249001912498\n0.1312671477935993\n0.13097318298268532\n0.13068058667302035\n0.130389350032324\n0.13009946430838146\n0.1298109208280408\n0.12952371099622537\n0.12923782629496033\n0.12895325828241333\n0.1286699985919494\n0.12838803893119935\n0.1281073710811419\n0.12782798689519928\n0.1275498782983461\n0.1272730372862306\n0.12699745592430983\n0.1267231263469964\n0.1264500407568186\n0.12617819142359193\n0.12590757068360361\n0.12563817093880836\n0.12536998465603605\n0.12510300436621127\n0.12483722266358413\n0.12457263220497203\n0.12430922570901301\n0.12404699595542955\n0.12378593578430346\n0.12352603809536124\n0.12326729584726964\n0.12300970205694214\n0.12275324979885482\n0.12249793220437268\n0.12224374246108559\n0.12199067381215413\n0.12173871955566445\n0.12148787304399326\n0.1212381276831815\n0.12098947693231733\n0.12074191430292784\n0.12049543335838028\n0.1202500277132912\n0.12000569103294427\n0.1197624170327172\n0.11952019947751624\n0.119279032181219\n0.11903890900612558\n0.11879982386241772\n0.11856177070762486\n0.11832474354609926\n0.11808873642849739\n0.11785374345126994\n0.11761975875615796\n0.1173867765296971\n0.11715479100272884\n0.11692379644991835\n0.11669378718927946\n0.11646475758170656\n0.11623670203051285\n0.11600961498097559\n0.11578349091988703\n0.11555832437511294\n0.11533410991515622\n0.11511084214872733\n0.11488851572432049\n0.11466712532979641\n0.11444666569196993\n0.1142271315762044\n0.11400851778601125\n0.11379081916265535\n0.11357403058476573\n0.113358146967952\n0.11314316326442575\n0.11292907446262779\n0.1127158755868598\n0.11250356169692172\n0.1122921278877539\n0.11208156928908418\n0.11187188106508002\n0.11166305841400509\n0.11145509656788084\n0.11124799079215257\n0.11104173638536023\n0.11083632867881354\n0.1106317630362715\n0.11042803485362628\n0.1102251395585917\n0.11002307261039551\n0.10982182949947593\n0.10962140574718224\n0.1094217969054797\n0.10922299855665803\n0.10902500631304388\n0.1088278158167172\n0.1086314227392315\n0.10843582278133741\n0.10824101167271032\n0.10804698517168153\n0.10785373906497252\n0.10766126916743338\n0.10746957132178404\n0.10727864139835928\n0.10708847529485695\n0.1068990689360892\n0.10671041827373733\n0.10652251928610962\n0.10633536797790213\n0.10614896037996276\n0.10596329254905837\n0.10577836056764446\n0.10559416054363846\n0.1054106886101952\n0.10522794092548556\n0.10504591367247805\n0.10486460305872268\n0.10468400531613799\n0.10450411670080036\n0.1043249334927363\n0.10414645199571688\n0.1039686685370553\n0.10379157946740611\n0.1036151811605678\n0.10343947001328703\n0.10326444244506593\n0.10309009489797111\n0.10291642383644527\n0.10274342574712131\n0.10257109713863821\n0.10239943454145933\n0.10222843450769312\n0.10205809361091539\n0.10188840844599432\n0.101719375628917\n0.10155099179661847\n0.10138325360681222\n0.10121615773782332\n0.10104970088842295\n0.10088387977766504\n0.10071869114472495\n0.10055413174873963\n0.10039019836865003\n0.10022688780304516\n0.10006419687000756\n0.0999021224069612\nLR accuracy score: 0.7321428571428571\nLR precision score: 0.7103242202541394\nLR recall score: 0.99\nLR f1 score: 0.8254196318954424\n"
    }
   ],
   "source": [
    "\n",
    "# %% Using evaluate_acc to do 5-fold CV\n",
    "\n",
    "# LOGISTIC REGRESSION MODEL \n",
    "# APPEND SCORES\n",
    "vali_acc_score_lr=[]; vali_preci_socre_lr=[]; vali_recall_score_lr=[];vali_f1_score_lr=[]\n",
    "# implement LR model \n",
    "import Models.logisticRegression as lr\n",
    "import Models.evaluate_acc as acc\n",
    "# LogReg1 =LogisticRegression()\n",
    "\n",
    "for i in range(5):\n",
    "    validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,i+1)\n",
    "    training_data_ion=training_data_ion.astype('int'); training_labels_ion=training_labels_ion.astype('int')\n",
    "    validate_data_ion=validate_data_ion.astype('int'); validate_labels_ion=validate_labels_ion.astype('int')\n",
    "    \n",
    "    # delete the previous loop's model \n",
    "    # if i > 0:\n",
    "    #    del LogReg1\n",
    " \n",
    "    ionslr1 = lr.Logistic_Regression(0.02,\"Ionosphere\",\"binary\")                # build model\n",
    "    params1 = ionslr1.fit(training_data_ion,training_labels_ion,0.02,1e-1)      # find parameters to predict \n",
    "    validate_pred_lr= ionslr1.predict(params1,validate_data_ion)                # predict on validation data \n",
    "    validate_pred_lr=validate_pred_lr * 1                                       # change True of False from validate_pred_lr into binary \n",
    "    \n",
    "    # accuracy score \n",
    "    validate_expect_lr = validate_labels_ion\n",
    "    tp, tn, fn, fp = acc.compute_tp_tn_fn_fp(validate_expect_lr,validate_pred_lr) # for other score computation \n",
    "    conf_mat = acc.compute_tp_tn_fn_fp(validate_expect_lr,validate_pred_lr)     # confusion matrix: (tp, tn, fn, fp)\n",
    "    validate_acc_score_lr = (acc.compute_accuracy(*list(conf_mat)))*0.01        # compute accuracy score   \n",
    "    vali_acc_score_lr.append(validate_acc_score_lr)                             # append validation accuracy score for each experiment \n",
    "    \n",
    "    # precision score \n",
    "    validate_preci_score_lr = acc.compute_precision(tp, fp)*0.01\n",
    "    vali_preci_socre_lr.append(validate_preci_score_lr)    \n",
    "\n",
    "    # recall score \n",
    "    validate_recall_score_lr = acc.compute_recall(tp, fn)*0.01\n",
    "    vali_recall_score_lr.append(validate_recall_score_lr)\n",
    "    \n",
    "    # f1 score \n",
    "    validate_f1_score_lr = acc.compute_f1_score(validate_expect_lr,validate_pred_lr)\n",
    "    vali_f1_score_lr.append(validate_f1_score_lr)\n",
    "    \n",
    "\n",
    "\n",
    "mu_vali_acc_lr=np.mean(vali_acc_score_lr); \n",
    "mu_vali_preci_lr=np.mean(vali_preci_socre_lr); \n",
    "mu_vali_recall_lr=np.mean(vali_recall_score_lr);\n",
    "mu_vali_f1_lr=np.mean(vali_f1_score_lr)\n",
    "print('LR accuracy score:',mu_vali_acc_lr)\n",
    "print('LR precision score:',mu_vali_preci_lr)\n",
    "print('LR recall score:',mu_vali_recall_lr)\n",
    "print('LR f1 score:',mu_vali_f1_lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "990667044\n0.11398343482676508\n0.11397351276566005\n0.11396359372170801\n0.11395367769326308\n0.11394376467868067\n0.11393385467631749\n0.11392394768453185\n0.11391404370168327\n0.11390414272613279\n0.11389424475624274\n0.11388434979037676\n0.11387445782689999\n0.11386456886417892\n0.11385468290058133\n0.11384479993447649\n0.1138349199642349\n0.11382504298822863\n0.11381516900483082\n0.11380529801241622\n0.11379543000936083\n0.11378556499404215\n0.11377570296483878\n0.11376584392013088\n0.1137559878582999\n0.11374613477772866\n0.1137362846768013\n0.1137264375539033\n0.11371659340742153\n0.11370675223574421\n0.11369691403726091\n0.11368707881036245\n0.11367724655344105\n0.1136674172648903\n0.11365759094310507\n0.11364776758648167\n0.11363794719341755\n0.11362812976231168\n0.11361831529156433\n0.11360850377957699\n0.11359869522475251\n0.11358888962549518\n0.11357908698021055\n0.11356928728730535\n0.11355949054518794\n0.1135496967522676\n0.11353990590695523\n0.11353011800766305\n0.11352033305280433\n0.113510551040794\n0.11350077197004793\n0.11349099583898357\n0.11348122264601965\n0.11347145238957611\n0.11346168506807422\n0.11345192067993652\n0.113442159223587\n0.11343240069745072\n0.11342264509995433\n0.11341289242952547\n0.11340314268459321\n0.11339339586358799\n0.11338365196494134\n0.11337391098708638\n0.11336417292845719\n0.1133544377874894\n0.11334470556261969\n0.11333497625228621\n0.11332524985492827\n0.11331552636898658\n0.11330580579290302\n0.11329608812512085\n0.1132863733640844\n0.11327666150823955\n0.11326695255603325\n0.11325724650591378\n0.11324754335633072\n0.11323784310573481\n0.1132281457525783\n0.11321845129531438\n0.1132087597323977\n0.1131990710622842\n0.1131893852834309\n0.11317970239429626\n0.11317002239333988\n0.11316034527902266\n0.11315067104980679\n0.11314099970415566\n0.11313133124053384\n0.11312166565740729\n0.11311200295324317\n0.11310234312650982\n0.11309268617567694\n0.1130830320992153\n0.11307338089559713\n0.11306373256329565\n0.11305408710078556\n0.11304444450654262\n0.11303480477904393\n0.11302516791676775\n0.1130155339181936\n0.11300590278180228\n0.11299627450607573\n0.11298664908949711\n0.11297702653055096\n0.11296740682772284\n0.11295778997949969\n0.11294817598436956\n0.11293856484082179\n0.11292895654734694\n0.1129193511024367\n0.1129097485045841\n0.11290014875228327\n0.11289055184402962\n0.11288095777831973\n0.11287136655365143\n0.11286177816852377\n0.11285219262143689\n0.11284260991089226\n0.11283303003539254\n0.11282345299344151\n0.1128138787835442\n0.11280430740420687\n0.11279473885393694\n0.112785173131243\n0.11277561023463491\n0.1127660501626236\n0.11275649291372135\n0.11274693848644157\n0.11273738687929875\n0.11272783809080865\n0.11271829211948829\n0.1127087489638558\n0.11269920862243044\n0.11268967109373274\n0.11268013637628438\n0.11267060446860817\n0.11266107536922819\n0.11265154907666963\n0.11264202558945889\n0.11263250490612346\n0.11262298702519209\n0.11261347194519473\n0.11260395966466241\n0.1125944501821273\n0.11258494349612286\n0.11257543960518364\n0.1125659385078454\n0.11255644020264491\n0.11254694468812029\n0.11253745196281073\n0.11252796202525658\n0.11251847487399938\n0.11250899050758177\n0.11249950892454755\n0.11249003012344173\n0.11248055410281044\n0.11247108086120094\n0.11246161039716157\n0.112452142709242\n0.1124426777959929\n0.11243321565596615\n0.11242375628771469\n0.11241429968979268\n0.1124048458607554\n0.1123953947991593\n0.11238594650356187\n0.11237650097252176\n0.11236705820459886\n0.11235761819835413\n0.1123481809523496\n0.11233874646514848\n0.11232931473531516\n0.11231988576141506\n0.11231045954201478\n0.11230103607568208\n0.11229161536098572\n0.11228219739649573\n0.11227278218078311\n0.11226336971242017\n0.11225395998998013\n0.11224455301203749\n0.11223514877716771\n0.11222574728394757\n0.11221634853095477\n0.11220695251676824\n0.11219755923996792\n0.112188168699135\n0.11217878089285156\n0.11216939581970105\n0.11216001347826782\n0.11215063386713742\n0.11214125698489646\n0.1121318828301327\n0.11212251140143496\n0.11211314269739309\n0.1121037767165982\n0.11209441345764241\n0.11208505291911884\n0.11207569509962187\n0.11206633999774693\n0.1120569876120904\n0.11204763794124994\n0.1120382909838242\n0.11202894673841288\n0.1120196052036169\n0.1120102663780381\n0.11200093026027953\n0.11199159684894522\n0.11198226614264041\n0.11197293813997126\n0.11196361283954512\n0.1119542902399704\n0.11194497033985658\n0.1119356531378142\n0.11192633863245487\n0.11191702682239123\n0.11190771770623713\n0.11189841128260734\n0.11188910755011776\n0.11187980650738538\n0.11187050815302814\n0.11186121248566523\n0.11185191950391678\n0.11184262920640398\n0.11183334159174912\n0.1118240566585755\n0.11181477440550758\n0.11180549483117073\n0.11179621793419153\n0.11178694371319749\n0.11177767216681721\n0.11176840329368036\n0.11175913709241768\n0.11174987356166091\n0.11174061270004285\n0.11173135450619733\n0.11172209897875933\n0.11171284611636473\n0.1117035959176505\n0.11169434838125475\n0.11168510350581652\n0.11167586128997585\n0.11166662173237404\n0.11165738483165306\n0.11164815058645632\n0.11163891899542802\n0.11162969005721335\n0.11162046377045882\n0.11161124013381162\n0.1116020191459202\n0.11159280080543393\n0.11158358511100339\n0.11157437206127988\n0.11156516165491592\n0.11155595389056511\n0.11154674876688188\n0.11153754628252185\n0.11152834643614164\n0.11151914922639874\n0.11150995465195189\n0.11150076271146057\n0.1114915734035856\n0.11148238672698858\n0.11147320268033213\n0.11146402126228003\n0.11145484247149688\n0.11144566630664848\n0.1114364927664015\n0.1114273218494237\n0.11141815355438384\n0.11140898787995161\n0.11139982482479774\n0.11139066438759403\n0.11138150656701325\n0.11137235136172906\n0.11136319877041628\n0.11135404879175065\n0.11134490142440892\n0.11133575666706881\n0.11132661451840906\n0.11131747497710939\n0.11130833804185067\n0.11129920371131435\n0.11129007198418339\n0.11128094285914138\n0.11127181633487297\n0.11126269241006391\n0.11125357108340081\n0.11124445235357135\n0.11123533621926414\n0.11122622267916879\n0.11121711173197593\n0.11120800337637707\n0.11119889761106481\n0.11118979443473267\n0.11118069384607515\n0.11117159584378779\n0.11116250042656702\n0.11115340759311021\n0.11114431734211588\n0.11113522967228334\n0.11112614458231296\n0.11111706207090608\n0.11110798213676497\n0.11109890477859288\n0.11108982999509405\n0.11108075778497371\n0.11107168814693794\n0.11106262107969388\n0.11105355658194963\n0.1110444946524142\n0.11103543528979762\n0.11102637849281086\n0.11101732426016579\n0.1110082725905753\n0.11099922348275329\n0.11099017693541445\n0.11098113294727456\n0.11097209151705031\n0.11096305264345932\n0.11095401632522026\n0.11094498256105252\n0.11093595134967678\n0.1109269226898143\n0.11091789658018757\n0.11090887301951992\n0.11089985200653557\n0.11089083353995982\n0.11088181761851869\n0.11087280424093945\n0.11086379340594997\n0.11085478511227936\n0.11084577935865748\n0.11083677614381518\n0.11082777546648426\n0.11081877732539741\n0.11080978171928837\n0.11080078864689166\n0.11079179810694283\n0.11078281009817831\n0.11077382461933544\n0.11076484166915261\n0.1107558612463691\n0.11074688334972492\n0.11073790797796125\n0.11072893512982011\n0.11071996480404447\n0.11071099699937813\n0.1107020317145658\n0.11069306894835335\n0.11068410869948735\n0.11067515096671524\n0.11066619574878554\n0.11065724304444768\n0.11064829285245184\n0.11063934517154929\n0.11063040000049217\n0.11062145733803347\n0.11061251718292715\n0.11060357953392799\n0.11059464438979187\n0.11058571174927537\n0.11057678161113613\n0.1105678539741325\n0.11055892883702405\n0.11055000619857093\n0.11054108605753443\n0.1105321684126766\n0.11052325326276045\n0.11051434060654985\n0.11050543044280958\n0.11049652277030547\n0.11048761758780407\n0.11047871489407272\n0.11046981468787996\n0.11046091696799504\n0.11045202173318815\n0.11044312898223024\n0.11043423871389353\n0.11042535092695059\n0.11041646562017533\n0.11040758279234227\n0.11039870244222703\n0.11038982456860598\n0.11038094917025638\n0.11037207624595649\n0.11036320579448526\n0.11035433781462269\n0.11034547230514959\n0.11033660926484766\n0.11032774869249952\n0.11031889058688861\n0.1103100349467993\n0.11030118177101676\n0.11029233105832713\n0.11028348280751736\n0.11027463701737533\n0.11026579368668973\n0.11025695281425016\n0.1102481143988471\n0.11023927843927186\n0.1102304449343167\n0.11022161388277465\n0.11021278528343965\n0.11020395913510651\n0.11019513543657096\n0.11018631418662951\n0.11017749538407953\n0.1101686790277193\n0.11015986511634805\n0.11015105364876565\n0.11014224462377294\n0.11013343804017177\n0.11012463389676462\n0.1101158321923549\n0.11010703292574696\n0.11009823609574595\n0.1100894417011578\n0.1100806497407894\n0.11007186021344847\n0.11006307311794358\n0.11005428845308401\n0.11004550621768025\n0.11003672641054323\n0.11002794903048495\n0.11001917407631821\n0.11001040154685676\n0.11000163144091499\n0.10999286375730827\n0.10998409849485283\n0.10997533565236564\n0.10996657522866464\n0.10995781722256845\n0.10994906163289676\n0.10994030845846987\n0.10993155769810904\n0.10992280935063638\n0.10991406341487472\n0.10990531988964791\n0.10989657877378045\n0.10988784006609778\n0.10987910376542623\n0.1098703698705928\n0.10986163838042537\n0.10985290929375277\n0.1098441826094045\n0.10983545832621112\n0.10982673644300366\n0.10981801695861432\n0.10980929987187595\n0.10980058518162222\n0.10979187288668776\n0.10978316298590786\n0.10977445547811873\n0.10976575036215741\n0.10975704763686166\n0.10974834730107019\n0.1097396493536225\n0.1097309537933588\n0.10972226061912023\n0.1097135698297487\n0.109704881424087\n0.10969619540097866\n0.10968751175926802\n0.10967883049780033\n0.10967015161542157\n0.10966147511097842\n0.10965280098331863\n0.10964412923129069\n0.10963545985374372\n0.10962679284952784\n0.10961812821749392\n0.10960946595649351\n0.10960080606537918\n0.1095921485430042\n0.10958349338822264\n0.10957484059988938\n0.10956619017686008\n0.1095575421179913\n0.10954889642214026\n0.10954025308816506\n0.10953161211492464\n0.10952297350127864\n0.1095143372460876\n0.10950570334821272\n0.10949707180651617\n0.10948844261986077\n0.10947981578711019\n0.10947119130712893\n0.10946256917878218\n0.10945394940093608\n0.10944533197245739\n0.10943671689221382\n0.1094281041590737\n0.10941949377190631\n0.10941088572958163\n0.1094022800309704\n0.10939367667494426\n0.10938507566037552\n0.10937647698613735\n0.10936788065110364\n0.1093592866541491\n0.10935069499414926\n0.10934210566998039\n0.1093335186805195\n0.10932493402464448\n0.10931635170123387\n0.1093077717091671\n0.10929919404732434\n0.10929061871458655\n0.10928204570983543\n0.10927347503195346\n0.10926490667982396\n0.10925634065233092\n0.10924777694835923\n0.10923921556679445\n0.10923065650652286\n0.10922209976643167\n0.10921354534540877\n0.10920499324234277\n0.10919644345612327\n0.10918789598564033\n0.10917935082978492\n0.10917080798744885\n0.10916226745752464\n0.10915372923890543\n0.10914519333048535\n0.10913665973115917\n0.10912812843982242\n0.1091195994553715\n0.10911107277670341\n0.109102548402716\n0.10909402633230783\n0.10908550656437833\n0.10907698909782756\n0.10906847393155639\n0.10905996106446646\n0.10905145049546014\n0.10904294222344056\n0.1090344362473116\n0.10902593256597788\n0.10901743117834484\n0.10900893208331862\n0.10900043527980599\n0.10899194076671478\n0.10898344854295328\n0.10897495860743057\n0.10896647095905668\n0.10895798559674211\n0.10894950251939829\n0.10894102172593734\n0.10893254321527218\n0.10892406698631633\n0.10891559303798425\n0.1089071213691909\n0.10889865197885223\n0.10889018486588484\n0.10888172002920592\n0.10887325746773356\n0.10886479718038669\n0.10885633916608471\n0.10884788342374793\n0.10883942995229737\n0.10883097875065476\n0.1088225298177426\n0.10881408315248406\n0.10880563875380313\n0.10879719662062447\n0.10878875675187351\n0.10878031914647633\n0.10877188380335985\n0.10876345072145163\n0.10875501989968006\n0.1087465913369742\n0.10873816503226381\n0.10872974098447936\n0.10872131919255214\n0.10871289965541411\n0.108704482371998\n0.10869606734123712\n0.10868765456206572\n0.10867924403341854\n0.10867083575423121\n0.10866242972344009\n0.10865402593998216\n0.10864562440279513\n0.10863722511081754\n0.10862882806298846\n0.10862043325824783\n0.10861204069553632\n0.10860365037379519\n0.10859526229196649\n0.10858687644899304\n0.10857849284381825\n0.10857011147538631\n0.10856173234264217\n0.10855335544453144\n0.10854498078000031\n0.108536608347996\n0.10852823814746611\n0.10851987017735919\n0.1085115044366243\n0.10850314092421143\n0.10849477963907102\n0.10848642058015447\n0.10847806374641367\n0.10846970913680137\n0.10846135675027092\n0.10845300658577654\n0.1084446586422729\n0.10843631291871554\n0.10842796941406069\n0.10841962812726519\n0.10841128905728672\n0.10840295220308356\n0.10839461756361474\n0.10838628513783989\n0.10837795492471947\n0.10836962692321458\n0.10836130113228697\n0.1083529775508992\n0.1083446561780144\n0.10833633701259643\n0.1083280200536099\n0.10831970530002002\n0.10831139275079286\n0.10830308240489495\n0.10829477426129362\n0.10828646831895701\n0.10827816457685371\n0.1082698630339532\n0.10826156368922553\n0.10825326654164157\n0.10824497159017267\n0.10823667883379104\n0.10822838827146952\n0.1082200999021816\n0.10821181372490153\n0.10820352973860414\n0.10819524794226508\n0.10818696833486055\n0.10817869091536748\n0.10817041568276355\n0.10816214263602693\n0.10815387177413675\n0.10814560309607256\n0.10813733660081477\n0.10812907228734428\n0.10812081015464287\n0.10811255020169286\n0.10810429242747732\n0.10809603683097992\n0.10808778341118506\n0.10807953216707783\n0.10807128309764391\n0.10806303620186977\n0.10805479147874246\n0.10804654892724973\n0.10803830854637994\n0.10803007033512228\n0.10802183429246644\n0.10801360041740284\n0.10800536870892262\n0.10799713916601747\n0.10798891178767993\n0.10798068657290297\n0.10797246352068038\n0.10796424263000665\n0.10795602389987678\n0.1079478073292866\n0.1079395929172325\n0.10793138066271148\n0.10792317056472132\n0.10791496262226044\n0.10790675683432788\n0.10789855319992339\n0.10789035171804726\n0.1078821523877006\n0.10787395520788506\n0.10786576017760298\n0.10785756729585742\n0.10784937656165201\n0.107841187973991\n0.10783300153187947\n0.10782481723432301\n0.10781663508032785\n0.10780845506890091\n0.10780027719904983\n0.10779210146978281\n0.10778392788010875\n0.10777575642903715\n0.10776758711557831\n0.10775941993874283\n0.10775125489754242\n0.10774309199098908\n0.10773493121809564\n0.10772677257787551\n0.10771861606934273\n0.10771046169151205\n0.1077023094433988\n0.10769415932401899\n0.1076860113323893\n0.10767786546752695\n0.10766972172844988\n0.1076615801141767\n0.10765344062372666\n0.10764530325611951\n0.10763716801037582\n0.10762903488551669\n0.1076209038805639\n0.10761277499453986\n0.10760464822646758\n0.10759652357537082\n0.10758840104027385\n0.1075802806202016\n0.10757216231417975\n0.10756404612123445\n0.10755593204039257\n0.10754782007068157\n0.10753971021112971\n0.10753160246076551\n0.10752349681861859\n0.1075153932837189\n0.10750729185509703\n0.1074991925317843\n0.10749109531281262\n0.10748300019721453\n0.10747490718402318\n0.10746681627227236\n0.10745872746099652\n0.1074506407492307\n0.10744255613601052\n0.10743447362037237\n0.10742639320135307\n0.10741831487799022\n0.10741023864932198\n0.10740216451438715\n0.10739409247222516\n0.10738602252187601\n0.10737795466238034\n0.10736988889277947\n0.10736182521211529\n0.10735376361943026\n0.10734570411376765\n0.10733764669417106\n0.10732959135968492\n0.10732153810935421\n0.10731348694222463\n0.10730543785734221\n0.10729739085375394\n0.10728934593050725\n0.10728130308665015\n0.10727326232123133\n0.1072652236333001\n0.10725718702190638\n0.10724915248610063\n0.10724112002493404\n0.10723308963745831\n0.10722506132272575\n0.10721703507978944\n0.10720901090770285\n0.10720098880552015\n0.1071929687722962\n0.10718495080708629\n0.10717693490894649\n0.10716892107693339\n0.10716090931010415\n0.10715289960751669\n0.10714489196822936\n0.10713688639130119\n0.10712888287579181\n0.10712088142076141\n0.10711288202527089\n0.1071048846883817\n0.1070968894091558\n0.10708889618665585\n0.10708090501994517\n0.10707291590808744\n0.10706492885014728\n0.1070569438451896\n0.10704896089228007\n0.1070409799904849\n0.10703300113887095\n0.10702502433650561\n0.10701704958245696\n0.10700907687579356\n0.10700110621558465\n0.10699313760090003\n0.10698517103081008\n0.10697720650438582\n0.10696924402069885\n0.10696128357882127\n0.10695332517782595\n0.10694536881678621\n0.10693741449477588\n0.1069294622108697\n0.10692151196414268\n0.10691356375367063\n0.10690561757852975\n0.10689767343779698\n0.1068897313305498\n0.10688179125586628\n0.10687385321282514\n0.10686591720050552\n0.1068579832179873\n0.10685005126435088\n0.10684212133867728\n0.10683419344004805\n0.10682626756754536\n0.10681834372025195\n0.10681042189725119\n0.10680250209762693\n0.10679458432046371\n0.10678666856484655\n0.10677875482986114\n0.1067708431145937\n0.10676293341813102\n0.10675502573956056\n0.10674712007797019\n0.10673921643244849\n0.10673131480208464\n0.10672341518596824\n0.1067155175831896\n0.10670762199283963\n0.10669972841400965\n0.1066918368457917\n0.10668394728727834\n0.10667605973756278\n0.10666817419573867\n0.10666029066090028\n0.10665240913214255\n0.10664452960856087\n0.10663665208925124\n0.1066287765733102\n0.10662090305983499\n0.10661303154792323\n0.10660516203667322\n0.10659729452518386\n0.10658942901255451\n0.10658156549788517\n0.10657370398027642\n0.10656584445882933\n0.10655798693264565\n0.10655013140082752\n0.10654227786247784\n0.10653442631669997\n0.1065265767625979\n0.10651872919927599\n0.10651088362583945\n0.10650304004139387\n0.10649519844504543\n0.10648735883590088\n0.10647952121306749\n0.10647168557565317\n0.1064638519227664\n0.10645602025351614\n0.10644819056701191\n0.10644036286236391\n0.10643253713868264\n0.10642471339507945\n0.1064168916306661\n0.10640907184455493\n0.10640125403585882\n0.10639343820369124\n0.10638562434716614\n0.10637781246539811\n0.1063700025575023\n0.10636219462259433\n0.1063543886597904\n0.10634658466820734\n0.10633878264696246\n0.10633098259517358\n0.10632318451195912\n0.10631538839643813\n0.10630759424773012\n0.10629980206495507\n0.10629201184723375\n0.1062842235936872\n0.10627643730343725\n0.10626865297560609\n0.10626087060931655\n0.10625309020369203\n0.10624531175785637\n0.10623753527093405\n0.10622976074205012\n0.1062219881703301\n0.10621421755489999\n0.10620644889488653\n0.10619868218941686\n0.10619091743761863\n0.10618315463862026\n0.10617539379155036\n0.1061676348955384\n0.10615987794971422\n0.10615212295320826\n0.10614436990515148\n0.10613661880467544\n0.10612886965091203\n0.10612112244299399\n0.10611337718005433\n0.10610563386122676\n0.10609789248564545\n0.10609015305244521\n0.10608241556076116\n0.10607468000972926\n0.10606694639848573\n0.10605921472616751\n0.10605148499191196\n0.1060437571948571\n0.10603603133414133\n0.10602830740890366\n0.10602058541828369\n0.10601286536142143\n0.10600514723745755\n0.10599743104553307\n0.10598971678478981\n0.10598200445436984\n0.105974294053416\n0.10596658558107142\n0.10595887903648\n0.10595117441878596\n0.10594347172713417\n0.10593577096067006\n0.10592807211853945\n0.1059203751998888\n0.10591268020386509\n0.1059049871296157\n0.10589729597628866\n0.10588960674303256\n0.10588191942899638\n0.10587423403332975\n0.10586655055518275\n0.10585886899370595\n0.10585118934805056\n0.1058435116173682\n0.10583583580081106\n0.10582816189753191\n0.10582048990668383\n0.10581281982742073\n0.10580515165889684\n0.10579748540026684\n0.10578982105068616\n0.10578215860931058\n0.10577449807529646\n0.10576683944780062\n0.10575918272598048\n0.1057515279089939\n0.1057438749959993\n0.10573622398615568\n0.10572857487862242\n0.10572092767255946\n0.1057132823671273\n0.10570563896148694\n0.10569799745479984\n0.10569035784622804\n0.10568272013493404\n0.10567508432008098\n0.10566745040083228\n0.10565981837635206\n0.1056521882458049\n0.10564456000835593\n0.10563693366317063\n0.1056293092094152\n0.10562168664625624\n0.10561406597286084\n0.10560644718839665\n0.10559883029203178\n0.10559121528293494\n0.10558360216027525\n0.10557599092322241\n0.10556838157094649\n0.10556077410261833\n0.10555316851740892\n0.10554556481449004\n0.10553796299303389\n0.10553036305221318\n0.10552276499120108\n0.10551516880917126\n0.10550757450529799\n0.10549998207875588\n0.10549239152872023\n0.10548480285436673\n0.10547721605487158\n0.10546963112941149\n0.10546204807716368\n0.1054544668973059\n0.1054468875890163\n0.10543931015147362\n0.1054317345838571\n0.10542416088534637\n0.10541658905512173\n0.1054090190923639\n0.10540145099625396\n0.1053938847659737\n0.10538632040070527\n0.10537875789963143\n0.10537119726193526\n0.10536363848680055\n0.10535608157341145\n0.10534852652095258\n0.10534097332860913\n0.10533342199556679\n0.10532587252101171\n0.10531832490413047\n0.10531077914411027\n0.10530323524013868\n0.1052956931914039\n"
    }
   ],
   "source": [
    "# QUESTION 3 PART 2\n",
    "# For task 3-2, CV is required to get the averaged training/validation accuracy for each learning rate (based on your choice). \n",
    "# After that, you can select the learning rate with the highest e.g. validation accuracy \n",
    "# and plot the train/validation acc - iteration figure using that best learning rate.\n",
    "# When plotting, you can either plot figures on all k-folds training-validation split (k training acc -iteration figure, k val acc - iteration figure) \n",
    "# OR you can just plot figures on a selected training-validation split of your choice (1 training acc - iteration figure, 1 val acc - iteration figure). \n",
    "# The former can be seen as a bonus.\n",
    "import numpy as np\n",
    "import Models.kfold_CV_try as cv\n",
    "\n",
    "learningRate=np.linspace(0.001,5,500); \n",
    "acc_learningRate=[]\n",
    "\n",
    "for j in enumerate(learningRate):\n",
    "    lRate = j[1]\n",
    "    vali_acc_score_lr=[]\n",
    "    for i in range(5):\n",
    "        validate_data_ion,validate_labels_ion,training_data_ion,training_labels_ion = cv.train_validation_split(cv_train_data_ion,cv_train_label_ion,i+1)\n",
    "#        training_data_ion=training_data_ion.astype('int'); training_labels_ion=training_labels_ion.astype('int')\n",
    "#        validate_data_ion=validate_data_ion.astype('int'); validate_labels_ion=validate_labels_ion.astype('int')\n",
    "        \n",
    "        ionslr1 = lr.Logistic_Regression(0.02,\"Ionosphere\",\"binary\")                # build model\n",
    "        params1 = ionslr1.fit(training_data_ion,training_labels_ion,lRate,1e-1)      # find parameters to predict \n",
    "        validate_pred_lr= ionslr1.predict(params1,validate_data_ion)                # predict on validation data \n",
    "        validate_pred_lr=validate_pred_lr * 1                                       # change True of False from validate_pred_lr into binary \n",
    "        \n",
    "        # accuracy score \n",
    "        validate_expect_lr = validate_labels_ion\n",
    "        tp, tn, fn, fp = acc.compute_tp_tn_fn_fp(validate_expect_lr,validate_pred_lr) # for other score computation \n",
    "        conf_mat = acc.compute_tp_tn_fn_fp(validate_expect_lr,validate_pred_lr)     # confusion matrix: (tp, tn, fn, fp)\n",
    "        validate_acc_score_lr = (acc.compute_accuracy(*list(conf_mat)))*0.01        # compute accuracy score   \n",
    "        vali_acc_score_lr.append(validate_acc_score_lr)                             # append validation accuracy score for each experiment \n",
    "\n",
    "    mu_vali_acc_lr=np.mean(vali_acc_score_lr); \n",
    "    acc_learningRate.append(mu_vali_acc_lr)\n",
    "    \n",
    "max_ionAcc = np.max(acc_learningRate)\n",
    "max_lRate = learningRate[acc_learningRate.index(max_ionAcc)]  # Find the x value corresponding to the maximum y value\n",
    "\n",
    "print('max acc score is ', max_ionAcc, 'at learning rate',max_lRate )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Now fitting ionosphere\n[1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0]\n(224, 2)\n(224, 34)\n(224, 34)\n(224, 2)\n(2, 34)\n(2, 34)\nlog prior\n[[-1.0171969 ]\n [-0.44880142]]\nlikelihood \n[[-2.55647005e+00 -7.08733425e-03 -1.63219021e+01 -1.48095565e+01\n  -2.48239598e+00 -1.32848651e+01 -1.01943301e+00 -7.10585277e+00\n  -1.14330133e+01 -9.82395976e-01 -3.44535894e+00 -5.58116141e+00\n  -7.08733425e-03 -1.23589392e+01 -7.08733425e-03 -7.08733425e-03\n  -7.08733425e-03 -7.08733425e-03 -7.08733425e-03 -7.08733425e-03\n  -1.55647005e+00 -5.19433013e-01 -9.94741655e-01 -2.95770462e+00\n  -7.08733425e-03 -1.50708733e+00 -7.08733425e-03 -5.07087334e-01\n  -7.08733425e-03 -1.55647005e+00 -4.49474166e+00 -7.08733425e-03\n  -7.08733425e-03 -7.08733425e-03 -3.43301326e+00 -7.08733425e-03\n  -2.45770462e+00 -2.94535894e+00 -7.08733425e-03 -7.08733425e-03\n  -5.07087334e-01 -1.14083219e+01 -7.08733425e-03 -4.82395976e-01\n  -1.00708733e+00 -4.45358939e-01 -2.45770462e+00 -2.47005030e+00\n  -5.07087334e-01 -3.04412437e+00 -1.47005030e+00 -7.78486511e+00\n  -7.08733425e-03 -7.08733425e-03 -7.08733425e-03 -7.08733425e-03]\n [-2.48503594e+00 -6.01496406e-03 -1.60724485e+01 -1.46353856e+01\n  -2.44307790e+00 -1.30864345e+01 -1.02699399e+00 -7.08993105e+00\n  -1.14360849e+01 -9.43077901e-01 -3.28923175e+00 -5.47804294e+00\n  -6.01496406e-03 -1.25619590e+01 -6.01496406e-03 -6.01496406e-03\n  -6.01496406e-03 -6.01496406e-03 -6.01496406e-03 -6.01496406e-03\n  -1.52000098e+00 -4.71049929e-01 -9.71049929e-01 -2.99202895e+00\n  -6.01496406e-03 -1.38713385e+00 -6.01496406e-03 -4.64056922e-01\n  -6.01496406e-03 -1.54797301e+00 -4.35216881e+00 -6.01496406e-03\n  -6.01496406e-03 -6.01496406e-03 -3.34517580e+00 -6.01496406e-03\n  -2.33818280e+00 -2.81021077e+00 -6.01496406e-03 -6.01496406e-03\n  -5.13007971e-01 -1.14850359e+01 -6.01496406e-03 -4.85035943e-01\n  -9.71049929e-01 -4.85035943e-01 -2.38014084e+00 -2.33118979e+00\n  -5.26993985e-01 -3.18084014e+00 -1.39412685e+00 -7.64937161e+00\n  -6.01496406e-03 -6.01496406e-03 -6.01496406e-03 -6.01496406e-03]]\n(2, 56)\n(224,)\n(224,)\n(34, 224)\n"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (224,) (2,56) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b60cfb0a8e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mionnb\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaive_Bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ionosphere\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mionnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_ion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_ion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_data_ion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mionnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest_ion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/COMP551A1/Models/naive_bayes_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, training_data, training_labels, test_data)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbinary_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2182\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (224,) (2,56) "
     ]
    }
   ],
   "source": [
    "import Models.naive_bayes_v2 as nb \n",
    "import numpy as np \n",
    "feature_types= np.array([\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",\"continuous\",])\n",
    "\n",
    "ionnb= nb.Naive_Bayes(\"ionosphere\", \"binary\", feature_types)\n",
    "parameters= ionnb.fit(training_data_ion, training_labels_ion, validate_data_ion)\n",
    "results= ionnb.predict(xTest_ion, parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}