# COMP551A1
The first Mini Project for McGill's COMP551 (Applied Machine Learning) Course.
REPORT: https://www.overleaf.com/4772658939djnbshhyfzsq

Dataset sources:

- one(Ionosphere): this is a dataset where the goal is to predict whether a radar return from ionosphere is ‘good’ or ‘bad’. This radar data was collected by a system in Goose Bay, Labrador. Get it from: https://archive.ics.uci.edu/ml/datasets/ionosphere 
- two  (Adult Data Set): also known as “Census Income” dataset, this is a dataset where the goal is to predict the whether income exceeds $50K/yr based on census data. Get it from: https://archive.ics.uci.edu/ml/datasets/Adult 
- three (Immunotherapy Data Set): Get it from: https://archive.ics.uci.edu/ml/datasets/Immunotherapy+Dataset
- four: Glass. Get it from: 


Task devision: 

- Model implementation (Friday night)
  - Naive Bayes Model (Sabrina)
  - Logistic Regression Model (Grace)
  - Evaluation Accuracy (Yujing)
  - Script to run k-fold cross validation (All)

- Run experiments (Saturday)
- Use 5-fold cross validation to estimate performance in all of the experiments. Evaluate the performance using accuracy. 
- (At minimum):
  - 1. Compare the accuracy of naive Bayes and logistic regression on the four datasets.
  - 2. Testdifferentlearningratesforgradientdescentappliedtologisticregression. Useathresholdforchangeinthe value of the cost function as termination criteria, and plot the accuracy on train/validation set as a function of iterations of gradient descent. 
  - 3. Compare the accuracy of the two models as a function of the size of dataset (by controlling the training size). As an example, see Figure 1 here 1. 
  
  - (For creativity) 
      - build and implement other evaluation methods 
      - you might investigate different stopping criteria for the gradient descent in logistic regression, develop an automated approach to select a good subset of features (Grace)
      - some other creative ideas (Sabrina & Yujing)
      


   
   
  

